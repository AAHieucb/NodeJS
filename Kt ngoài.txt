# Hiểu về backdoor
-> Backdoor bắt thông tin của người dùng gửi về server của hacker, VD hoạt động dưới dạng 1 middleware bắt request của user.
VD: ta sử dụng 1 gói npm phổ biến A, trong gói A lại dùng package B, trong B có C nhưng thư viện C là 1 thư viện có backdoor mà chưa ai biết đến của hacker. Ta chỉ nên sử dụng các gói nổi tiếng, mã nguồn mở, sử dụng các công cụ giám sát các gói tin gửi đến máy chủ có gì lạ không

-> Backdoor là 1 cổng không public cho phép 1 người xâm nhập vào hệ thống. Dev có thể chủ động tạo ra, nếu không có mục đích xấu thì họ làm vậy để có thể tự mình xâm nhập vào hệ thống sửa lỗi và bảo dưỡng. Backdoor cũng có thể do dev cùi tạo ra app có backdoor ngoài ý muốn. 
Nhiều nơi, chính quyền còn bắt các nhà phát hành dịch vụ tạo ra các điểm truy cập là backdoor nhưng hợp pháp để nếu nhà nước dùng nó tìm ra tội phạm. Dev cũng có thể chủ ý cài backdoor xong lừa công ty đối thủ dùng nó. 
Nhiều loại backdoor nguy hiểm có thể tự nhân bản hay tự che giấu. VD các backdoor chạy tiến trình trùng tên với các tiến trình trong hệ thống để không bị phát hiện
=> Không sử dụng phần mềm không đáng tin, nên chạy ứng dụng test trong môi trường đóng và cung cấp ít quyền nhất có thể.

VD backdoor sử dụng với mục đích tốt: ta dùng anti virus sao nó báo cập nhập được. Thực tế, nó được cài phần mềm gián điệp liên tục gửi thông tin về version hiện tại cho server từ xa và server sẽ check phần mềm đó cần update không và người dùng nhận dược thông báo nếu có. Tương tự các phần mềm check bản quyền họ sẽ có chức năng kiểm tra xem người dùng có dùng sp có bản quyền không. Đương nhiên việc kiểm tra bắt buộc phải gửi request lên server r thì phải dùng backdoor.
Các website có thể có backdoor theo dõi người dùng đăng nhập và thực hiện hành động thông báo nào đó kiểu "Bạn vừa đăng nhập ở 1 thiết bị lạ". Cx là để bảo vệ khách hàng thôi.



# So sánh về memory giữa các ngôn ngữ, k xét tốc độ
Rust tokio vẫn là ngôn ngữ tốn ít memory nhất so với mọi ngôn ngữ khác
NodeJS tốn ít memory hơn C# khi có 100 ngàn task đồng thời, nhưng khi lên mức 1 triệu task thì C# tốn ít hơn NodeJS, hiẹu năng cũng cao hơn. Do đó dự án lớn ưu tiên dùng C#.
Go thì tốn memory ít khi chạy ít task nhưng số lượng task đồng thời tăng nhanh sẽ khiến nó tốn lượng memory tăng vọt. Python cũng vậy.



# Phân biệt 5 lĩnh vực:
Front end: HTML, CSS, Javascript / Bootstrap, Material UI / Angular React Vue/ Webpack
Backend: PHP, Python, NodeJS, Ruby on Rails, ASP.NET, DJANGO, Java(Spring)
Database: (RDBMS) MsSQL, MySQL, Postgre / (No SQL) MongoDB, Cassandra, Elasticsearch, Redis, CouchDB / (Graph) Neo4J, ArangoDB / (Message Queues) Kafka, SQS, ZeroMQ, RabbitMQ / (Cloud) Oracle, Firebase
DevOps: (Infrasstructure) AWS, Azure, NGINX / (Automation) Ansible, Chef, Jenkins / (Virtualization) Docker, BladeCenter, VMware, Vagrant, Kubernetes
Android: (Android) Java, Kotlin, SDK / (iOS) Objective-C, Swift / (Cross platform) React Native, Ionic, Xamarin, Unity, PAW / Qt, QML



# Event loop của nodejs
Event liên tục được bắt để add vào queue theo thứ tự: Timer event(timeout,interval) -> IO callback-> Idle(nội bộ k qt)-> Poll(Tìm kiếm sự kiện IO mới đang polling) -> Check(xử lý callback của setImmediate)-> Close Callbacks(xử lý các callback ngắt kết nối) -> quay lại Timer
Khi có event -> gửi event cho C++ xử lý, xong thì sẽ gửi callback cần thực hiện vào event queue của JS. 

VD: ta gọi setImmediate và setTimeout 0s cạnh nhau coi là cùng lúc, thì thứ tự sẽ phụ thuộc vào cái loop thêm event vào queue kia đang ở giai đoạn Check hay Timer. 
Nếu a cho setImmediate và setTimeout 0s vào vào 1 luồng IO/callback là fs.readFile thì chắc chắn setImmediate thực hiện trước setTimeout. NN là vì nó sang giai đoạn Check trước giai đoạn Timer kể từ IO/callback. setImmediate xử lý khi event queue chạy vào Check, còn setTimeout xử lý trong giai đoạn Timer.
VD: Khi loop hiện tại kết thúc, trước khi vòng sau bắt đầu sẽ thực hiện theo thứ tự: callback của process.nextTick(callback) -> promise -> callback của setImmediate(callback)

-> Phân tích
stack: nơi chứa các lệnh nó chạy theo thứ tự LIFO từ code của ta, thực hiện hàm lần lượt gọi là call stack
heap: nơi chứa các kết quả tạm phục vụ cho việc thực thi các hàm trong stack. Heap càng lớn thì tính toán càng nhanh. Trong C/C++ thì dùng nó là cấp phát động 
JS engine: là nền tảng thông dịch mã JS bao gồm heap và stack. NodeJS xây dựng trên JS engine là V8 Chorme
event: là thứ chứa các thông tin về sự kiện chờ xử lý
callback function và listener: là cái bind cùng với event, là cái sẽ được thực hiện khi event đó được gọi. 
EventLoop: event loop tồn tại trong Ct vĩnh viễn miễn CT chưa bị tắt. 
Mã nguồn core của nodejs: gồm 2 thành phần là javascript và C++ => C++ bao gồm các xử lý tới các thư viện bên ngoài quan trọng như V8, libuv.

-> Cơ chế: Mã nguồn của ta thực hiện tuần tự trong V8, gặp hàm thì đưa vào stack và thực hiện, dữ liệu hàm trả ra lưu vào heap. Nếu k có hàm bất đồng bộ thì sẽ thực hiện tuần tự r kết thúc. Nếu có hàm bất động bộ như callback, sự kiện,.. thì lời gọi đó như 1 request xử lý trong OS hoặc thực thi các WebAPI(quản lý bởi libuv của C++), lúc này stack kia vẫn thực hiện bth còn cái request kia đồng thời bị đẩy ra ngoài độc lập như v nhờ WebAPIs. Request này sẽ được core của CPU thực hiện, cái này do C++ dùng thread pool xử lý nên các tác vụ ở đây được xử lý đồng thời rồi mới đưa vào event queue(VD nếu ta dùng setTimeout 5s thì WebAPIs sẽ k gửi ngay mà 5s sau mới gửi hàm cho queue, nếu ta fetch API thì multithread của CPU sẽ xử lý). CV tốn thời gian đó sẽ được xử lý trên C++ Thread Pool, tức là xử lý multithread và còn cho phép ta tương tác với database, file system,.. Cái nào xong trước thì callback của nó sẽ được đưa vào event queue. Event loop kiểm tra nếu stack trống thì kiểm tra callback queue, stackqueue k có sự kiện thì loop vẫn có nhưng chả làm gì, nếu event queue có sự kiện thì nó sẽ xử lý. Nó sẽ xử lý yêu cầu và xác định hàm callback của yêu cầu đó gửi vào callstack để xử lý. Nếu callstack vẫn có dữ liệu thì eventqueue sẽ k làm gì cả, chờ stack thực hiện callback event đó xong trống mới vô đc, do đó nếu đưa vào event queue mà k đc thực hiện ngay vì trong queue đó có các thứ khác thì thời gian thực hiện có thể lâu hơn dẫn đến setTimeout chỉ là thời gian tối thiểu công việc chạy chứ kp thời gian chính xác.
VD cụ thể: ấn nút gọi setTimeout gọi hàm fetch API xong callback in ra màn hình. Compile đến sự kiện -> web APIs lưu nó -> emitter phát sự kiện -> web APIs bắt sự kiện -> đưa cho C++ thread pool xử lý, lúc này nó chả làm gì mà gửi luôn call back của sự kiện cho event queue. Trong lúc này Ct vẫn chạy đồng thời các sự kiện khác và bất đồng bộ thì vẫn đưa vào C++ thread pool xử lý, cái này với cái kia, cái nào xong trước thì gửi vào event queue trước thôi. Event loop lấy nó gửi sang stack. Stack thực hiện nó lại thấy 1 hàm bất đồng bộ là setTimeout lại gửi sang cho WebAPIs. Còn các hàm đồng bộ khác bên trong nó thì vẫn thực hiện tiếp. WebAPIs gửi nó cho thread pool xử lý. Sau ktg set Timeout pool đó sẽ đưa hàm callback của setTimeout vào queue r vào stack nếu stack trống r thực hiện -> thực hiện thì lại bắt gặp hàm fetch API -> lại đưa sang WebAPIs, nó lại đưa vào pool xử lý bất đồng bộ. Lúc này stack trống và có thể thực hiện tiếp các hàm khác. Pool thực hiện xong sẽ lại đưa callback của hàm đó vào event queue -> event loop lại lấy ra đưa vào stack để thực hiện nếu stack trống, lúc này sẽ thực hiện in ra màn hình



# So sánh cache redis
Redis có ACID và hiệu suất cao hơn db bth. Nó chỉ k thể thay thế các db như mysql vì k hỗ trợ truy vấn phức tạp như nối table, hay phân quyền bảo mật. 
Chú ý nếu k cần 2 tính năng đó cũng k nên lưu hết data vào cache vì redis dùng main memory nhỏ dễ bị tràn. 

Redis cung cấp nhiều tính năng như pub/sub, sự kiện, hỗ trợ kiểu dữ liệu phức tạp, có chế độ cluster, lưu data bền bỉ trong đĩa cứng, đơn luồng (nên mỗi lệnh là atomic)
VD: Redis hỗ trợ HyperLogLog là một cấu trúc dữ liệu xác định xấp xỉ số lượng phần tử duy nhất trong một tập hợp lớn mà không cần lưu trữ tất cả các phần tử đó
Memcached giống Redis nhưng thiếu nhiều tính năng, chỉ dùng với string, chỉ lưu trong memory restart là mất. Do đó nó cũng có hiệu suất cao hơn và tải công việc lớn hơn.
=> Ứng dụng nhỏ dùng memcached là được. Còn cần linh hoạt hay tính năng nâng cao thì dùng redis.



# Config SSMS kết nối được với mssql nodejs trên máy win (hoạt động tốt năm 2022)
Để tạo tài khoản mật khẩu và sử dụng: rightClick vào server -> property -> secure -> SQL Server and Window Authentication mode vì tk mk thì phải dùng mode SQL Server.
Vào SQL bằng window authentication(là nơi tạo ra các user) -> security -> rightclick login -> new login -> SQL Server authentication -> gõ password; server roles -> mặc định có public tức là tài khoản cho mọi người -> ta nên dùng tài khoản cho người và chỉ có 1 user tên là sa có quyền sysadmin mà thoi; User mapping: chọn các database muốn truy cập bởi user này -> check các quyền db_datawriter và db_datareader là các quyền cơ bản nhất đọc và viết với database, để 2 quyền đó hoạt động thì phải là chủ của database tức check thêm db_owner(k check sẽ lỗi); Status: grant và enabled; 
Restart lại server này: cmd computer management -> Services and Applications -> Services -> refresh lại SQL Server Browser, agent và service;
=> Có thể vào database với từng tài khoản r, tk đó chỉ truy cập vào được những database ta đã set mà thôi
=> Mỗi khi xóa hay làm gì trực tiếp trên database thì phải luôn luôn restart lại database và nếu có thể thì cả trong computer management.

Để dùng đc server ta cần setting lần đâu trên máy win (các lần sau k cần làm phần này nữa): computer management -> services and applications -> services -> start các thứ SQL Server Browser, SQL Server, SQL Server CEIP services; -> SQL Server Configuration Manager -> SQL Server Services-> start SQL Server Browser; -> SQL Server Network Configuration -> Protocols for SQLEXPRESS -> enabled cái TCP/IP -> IP Addresses -> active và enabled yes -> TCP Dynamic Ports blank -> TCP Port 1433



# Cache memory trong máy tính
Internal memory có 2 loại là cache và main memmory. External memory là CD hay hard drive
Cache còn nhanh hơn cả RAM, nhưng bộ nhớ ít. cache L1: là 1 phần của microprocessor chip; cache L2: bên ngoài chip, lớn hơn L1. Có 2 loại instruction cache và data cache.
Ứng dụng ban đầu lưu trên hard disk, mở lên sẽ lưu trong RAM, các tác vụ nhỏ sẽ lưu trên cache.

VD cache có số lượng ô nhớ là 8 block. Mà data có nhiều thì ta lấy address của data block %8 sẽ biết cần lưu nó vào block nào. Cache chỉ cần lưu higher order bit là mọi bits trừ 3 bits cuối ở đây. Sau đó có thể tự compute ra full khi lấy với: [high order bit] + [3 bits cuối là index of block trong cache] 

VD cache có 64 blocks và 1 block 16 bytes thì address 1200 sẽ ánh xạ đến block có thứ [1200/16]=75 vì 1 address refer đến 1 bytes mà. Block thứ 75 trong cache đâu có tồn tại nên nó phải refer đến cache block thứ 75%64=11 để biết hit hay miss

Vấn đề đồng bộ cache với main memory:
Write through: update cache với main mem đồng thời, sẽ bị chậm => thường dùng
Write back: chỉ update cache, khi data trong cache bị replaced mới update vào mainmem => chỉ dùng khi cache size lớn, cần tốc độ cao mà update main mem bị chậm

Multilevel cache: cache level1 chú trọng hit time ngắn, cache level2 lớn hơn chú trọng miss rate thấp để vừa có hit time ngắn và miss rate thấp. Nếu dùng 1 cache to đùng duy nhất rất khó đạt được điều này.

Cache dùng SRAM tốc độ cao hơn và có giới hạn vì giá đắt. 

-> 3 loại cache: Direct map, fullly associative, n way set associative
- Direct map dùng 1 bảng hash hash và lưu theo hash để tìm tốc độ O(1)

- Fully associative lưu mỗi cục block data là 1 cục block cache luôn, khi cần tìm sẽ search tuyến tính, lưu vị trí nào cũng được. VD cache có 8 entry thì 1 block có thể lưu vào bất cứ entry nào trong cache đó => Khi search sẽ ngốn O(n) với n là số entry trong cache, chậm hơn direct map O(1) nhưng ít miss hơn, cache size nên nhỏ thôi

- n way set associative thì cache lưu nhiều set theo hash search O(1), rồi search tuyến tính từng entry trong set.
VD: one way tức là số lượng set bằng số lượng entry và giống Direct map
VD: ta nhìn ký hiệu Cache Level2 4-way => tưc cache level2 dùng 4 entry trong 1 sets, level 1 k có thông tin nhưng nếu miss thì sẽ search trong level2
Với direct map ta chỉ có 1 cách để replace, còn với associative bắt đầu sinh ra nhiều PP để quyết định bỏ block nào khỏi cache khi 1 block mới cần được thêm vào. VD Dùng LRU là xóa bỏ cái k dùng đến trong ktg xa nhất => Nên dùng khi cần lưu lượng lớn data.



# Method OPTIONS 
Khi client gửi OPTIONS tới server, server phản hồi với thông tin chứa các HTTP Method mà client có thể sử dụng cho url đó. 
Trình duyệt tự động gửi preflight request như vậy khi FE và server ở 2 domain khác nhau để kiểm tra xem server có cho phép yêu cầu từ origin đó k, hoặc khi dùng method k an toàn như PATCH để update data. Cùng origin sẽ k gửi.
Đây là bảo mật mặc định của trình duyệt, server phải xử lý và trả về các header cors như Access-Control-Allow-Origin, Access-Control-Allow-Methods, Access-Control-Allow-Headers. Nếu không sẽ báo lỗi cors. Nó giúp ngăn chặn các request không mong muốn từ các nguồn k đáng tin khi tự động gửi request đến 1 server k chấp nhận kiểu request đó.
=> Đó là bản chất của same site policy. Khi cài package cors thì nodejs server tự xử lý điều đó cho ta thôi.



# Other
-> NodeJS xd trên nền tảng Javascript V8 Engine tốc độ cao, mã nguồn mở. Engine gồm heap và stack, tải NodeJS là tải engine này về
Javascript engine là trình thông dịch mã js. Ngoài V8 thì cũng có các js engine khác như: SpiderMonkey(FireFox), Hermes(ReactNative), Chakra(IE), JavascriptCore(Safari),..

-> Nếu tự implement cache key-val trong JS: 
Nên dùng con trỏ yếu như WeakMap 
Implement LRU cache, số lượng cố định, tràn tự xoá cái lâu nhất không dùng => tối ưu. Cũng có kiểu Least Frequently Used.

-> Các loại cache có sẵn khác:
--> Trong mạng internet cũng có DNS cache, ARP cache
VD: CDN server cung static data cũng có cache. Khi user request data k có trong CDN cache thì CDN server mới request tài nguyên này trên server gốc để lưu vào Cache

--> Load balancer tương tự cũng query từ server gốc lưu vào cache của nó. User khác cũng request same content thì có luôn
Message broker như Kafka cũng cache hàng loạt message trên disk của nó cho người dùng lấy nhanh
Full text search engine như Elastic search cũng dùng cache để cải thiện hiệu suất query của người dùng
Database cũng có plan cache, buffer pool lưu kết quả truy vấn, transaction, replication log.

-> In-Memory Cache là cache ngay trên các ứng dụng FE, Browser, DB, Server đang có
Distributed Cache thì cache là server độc lập, có thể 1, replica or nhiều server phân tán, giúp tăng hiệu suất, khả năng chịu lỗi.
Họ có thể chia cache nhiều tầng: dùng In-Memory Cache làm level 1, Distributed Cache cho level2. Khi restart API server thì In-Memory Cache mất, Distributed Cache vẫn ok.

-> Sharp: thư viện xử lý tối ưu hoá ảnh mạnh cho nodejs. Input ảnh vào và lấy ra đủ loại kích thước muốn blur hay chất lượng giảm như nào tuỳ
