# Tạo streaming server cho video
Dùng link youtube, ipfs, đăng lên cdn cloud tốt hơn là dựng hẳn 1 streaming server vì tốn, trừ các web chuyên về video k muốn phụ thuộc bên thứ 3.
Cơ chế streaming server: Mỗi đoạn của video khi xem sẽ gửi http request nhận về 1 lượng bytes kể từ vị trí đó trở đi và tiếp tục cho đến hết video, thông tin này nằm trong header. Ở FE, video player của html5 hỗ trợ sẵn việc gửi request đi và xử lý response nhận về như nào rồi, server chỉ cần gửi lại đúng format response là được

-> Cơ chế tính lượt view cho video không phải là số lần gọi request GET và cũng k yêu cầu phải lấy xem hết mọi bytes của video. 
VD chọn 1 mốc 30s và chia khoảng 30s đó khắp video thay đổi vị trí random liên tục. Vd 10s đầu ở đoạn 1p->1p10s, 10s sau ở 2p->2p10s, 10s cuối ở 3p50s->4p => user phải xem đúng các đoạn đó mới +1 view. 

VD 1 giải pháp chống spam view là lưu IP user vào cache tự hết hạn và bị xóa sau khoảng 5p. Mỗi khi định tăng view bởi 1 ip sẽ check ip vẫn có trong database thì k cộng view lên. Tức là người dùng refresh liên tục trong 5p sẽ k có tác dụng vì ip vẫn có trong DB, video length > 5p. Tức max 1 người trong 5p chỉ được 1 view.
=> Thực ra lưu ip k ổn VD nhiều người cùng bắt VPN hay chung mạng LAN sẽ k chuẩn, ta có thể tạo 1 userid ảo dù chưa login và lưu 1 id vào cookies chứ kp lưu ip, mỗi request phải gửi kèm cookies lên để server check.

VD các nghệ sĩ nổi tiếng khi cộng lượt view tăng quá nhanh, chắc chắn DB k thể sử dụng MySQL hay MongoDB mà phải sử dụng cache như redis.
Nên thêm ratelimit và black list chặn ip truy cập bất thường. VD 1 IP truy cập đồng thời tới cả nghìn lần 1p thì khá vô lý cho 1 mạng LAN thì sẽ bị chặn ngay. VD Dùng nginx làm reserve proxy có thể lấy được ip của user trong header trường X-Forwarded-For



# Dùng HTTP2 HTTP3
HTTP1 thì mỗi yêu cầu là 1 connection TCP riêng.

HTTP1.1 duy trì kết nối cho phép nhiều yêu cầu tới 1 server được xử lý trong cùng một kết nối TCP.
Head-of-Line Blocking là hiện tượng response request trước quá lâu làm cho các requests sau bị blocked. Http1.1 đỡ hơn vì có HTTP pipelining cho phép gửi nhiều request đồng thời trên cùng 1 TCP connection mà không cần chờ request trước done, nhưng response vẫn trả về phải đúng thứ tự trong 1 connection, nên HoL k đươc cản hoàn toàn.
Để đảm bảo k bị lỗi đơ luôn, browser duy trì nhiều TCP connection tới server và gửi song song, chứ k chỉ 1 connection.

HTTP2 dùng HTTP stream. Trong 1 TCP connection có thể gửi hàng loạt các stream request và các stream k cần đúng thứ tự nữa, giải quyết vấn đề Head-of-Line Blocking ở tầng application nhưng vẫn bị ở tầng transport với TCP: Client <--- 1 TCP connection [Stream1 header, stream2 header, stream1 data, stream3 header, ...] ---> Server
Server push new data tới client khi có update mà k cần client phải poll liên tục, giảm sô request. Dùng HPACK nén giảm kích thước header. Dùng binary format nhanh hơn so với định dạng văn bản của HTTP/1.x.

HTTP3 dùng protocol QUIC, dựa trên UDP ở ngay tầng transport nhưng nó chỉnh sửa để UDP mà tốt hơn TCP, vẫn có cơ chế phục hồi gói tin khi bị mất.
Client <--- 1 QUIC/UDP connection [Stream1, stream2, stream3, ...] ---> Server
QUIC cũng được dùng để đổi mạng trong điện thoại mà k bị lag vì dùng chung 1 connection id.

=> Cũng có thể dựng 1 proxy nginx server dùng HTTP2, khi đó sẽ k tận dụng hết dược sức mạnh của HTTP2: Client <-- HTTP2 --> Nginx <-- HTTP1.1 --> Server



//!!!!!!!!
# 3 cách connect db:
- K nên tạo 1 db connection global duy nhất dùng suốt dự án. Vì connection có thể đóng vì nhiều lý do mà ko biết như timeout hay lỗi mạng. Kể cả có setting reconnect hay sự kiện disconnect để gọi connect lại cũng k nên dùng
- Mỗi lần query sẽ khởi tạo connection và đóng ở cuối. Thường dùng cho các dự án lớn, query phức tạp.
- Connection pool là giải pháp tối ưu, query xong tự trả vào pool để tái sử dụng, setting config autoReconnect reconnectTries, tự đảm bảo connection k bị mất khi k sử dụng.
Néu server khởi động thành công mà connect db lỗi thì nên dừng ct, có thể throw error để dùng.



# Browser có sẵn cache
Cache browser phụ thuộc vào trường Cache-Control trong response header

- Header "Cache-Control" kiểm soát tài nguyên được cache như nào trong browser. Có thể kiểm soát có cache hay không, thời gian expires, lưu trữ cache trên proxy trung gian hay không => Nên set file css js ảnh là thời gian cực lâu, các api data đổi nhiều thì no-cache. 
Có thể tuỳ biến set cả cho FE (server host nó) hoặc set cho API server nodejs. Thực ra React host lên tự động cache các files tĩnh cần thiết mặc định rồi. Các proxy server như nginx apache thường luôn custom header này. Bth nếu k set thì mặc định dùng setting của browser, thg là no-cache Thường họ chỉ dùng Ca
- Header "Expires" trong response cũ hơn, nó xác định thời điểm cụ thể mà tài nguyên hết hạn trong cache.che-Control sẽ override bỏ qua trường Expires



# Hệ phân tán nhiều server thì query cái nào
Vấn đề muôn thuở của hệ phân tán: Khi dùng distributed cache, hoặc có nhiều api server và mỗi server dùng 1 cache riêng
Client query 1 server cache lưu có data rồi nhưng request sau query server khác không có phải get lại dẫn đến 1 data lưu ở nhiều server. Do đó nên dùng pp Hashing hoặc Sticky Sessions thay vì dùng Round Robin, Least Connections. Hashing sẽ hash thông tin client để lấy ra 1 server khiến cho mọi request của client luôn tới 1 server duy nhất.

Dùng Hashing gặp vấn đề khi server list biến động, lúc nào client cũng gọi vào server đó kể cả khi nó sập hay bị xoá rồi dẫn đến lỗi. Do đó họ dùng:
- Consistent Hashing: 
Dùng 1 hàm hash an toàn cho id của node và id của data record. Ra 1 giá trị thì nhét vào 1 vòng tròn. Mỗi key sẽ gắn với node gần nhất kề nó theo chiều kim. Vd:
0 ---- A ---- key1 ---- B ---- key2 ---- E ---- key3 ---- C ---- key4 ---- D ---- 2^32-1
Key 1 gắn node B, key 2 gắn node E. Nếu ngừoi dùng muốn query data có key 4 thì họ query vào cache server D. Thêm xoá server không sợ lỗi mà lại nhanh.
- Rendezvous Hashing: 
Muốn tìm node nào lưu record hiện tại, ta tính weight của data với từng node: weight(key, node) = hash(key of record + node_id) => Node có giá trị cao nhất sẽ lưu record đó.



# Chia file BE hệ thống lớn
Mục tiêu là nhìn code biết module nào gọi API làm gì, nhìn API trong UI biết ngay nó gọi ở phần code module nào
1) NodeJS: việc chia file khá hiển nhiên.
src
  api
    v1
    v2
      routes
        auth.route.js
        blog.route.js
      controllers
        auth.controller.js
        blog.controller.js
        index.js
      utils
        staticvalidationhelper.js
        staticutility.js
      middlewares
      models  
        blog.js
        bloguser.js
      services
        jwt.service.js
        blog.service.js
      validations
      logs
  config
    database.config.js
    redis.config.js
    index.js
tests
.env.dev
.env.prod
database.js => connect db
index.js => run main function
server.js => start server nodejs
test.http => test api

Cách khác là tùy biến chia theo module để navigate tới các hàm liên quan nhanh chóng tùy ý => k nên
src/api/v1/user
  user.service.js
  user.test.js
  user.model.js
  user.controller.js
  user.handler.js

2) ASP.NET hướng đối tượng phức tạp:
Smp.Web (dự án chính)
  Controllers (folder)
    Voice (folder)
      VoicePolicyController.cs
      VoiceUserController.cs
    Teams (folder)
    HomeController.cs
    EmailController.cs
  Attributes (folder)
    LicenseAttribute.cs
    AuditorAttribute.cs
  Middlewares (folder)
  Models (folder) => model mà chỉ dùng trong Smp.Web
  appsettings.Development.json
  appsettings.Production.json
  Program.cs => chạy hàm main
  Startup.cs => file setup

Voice (folder)
  Voice.Service (library)
    Actions (folder)
      VoiceScanPolicyAction.cs
      VoiceScanCallQueueAction.cs
    Interface (folder)
    Service (folder)
      VoicePolicyService.cs
      VoiceCallQueueService.cs

PowerPlatform (folder)
  PowerPlatform.Service (library)
    Impl (folder)
      PowerApps(folder)
        PowerPlatformPowerAppsService.cs
        PowerPlatformPowerAppsFromDBService.cs
      Environment (folder)

Common (folder)
  Smp.Database.Core (library)
  Smp.Common(library)
    Job (folder)
      IJobAction.cs
      JobContext.cs
    Helpers (folder)
      CipherHelper.cs
      LoginHelper.cs
    Models (folder)
      AuditorInfo.cs
      ProcessCenterModel.cs
  Smp.Service.Common (library)
    GraphClient (folder)
    Login (folder)
      LoginService.cs
      PrincipalService.cs
    Storage (folder)
      BlobStorageService.cs
      TableStorageService.cs

=> Ở cấp độ folder và dự án và library, dường như có thể chia tùy biến theo phạm vi trên nhìn rất rõ scope của từng phần.
Best practice là chia theo tính năng rồi viết từng module bên trong, k ai chia module trước, tính năng sau cả:
Tính năng của ngôn ngữ 1
  Tính năng con của ngôn ngữ 1
    Các folder chia theo từng module business (lại lồng nhau tiếp)
      Classes.cs

=> Nên tìm hiểu mỗi class thuộc kiểu gì, nằm ở đâu, và lấy ra dùng như thế nào, có 4 kiểu:
Class là static => là class mà gọi ở bất cứ đâu trong dự án miễn có reference, gọi dùng các hàm utility, dùng extension method, có thể lưu state (singleton) hoặc chỉ xử lý logic mà k lưu gì cả
Class là service => class service được DI vào bất cứ dự án server nào và lấy ra dùng trong các class khác
Class chuẩn có sẵn của C# => class C# yêu cầu phải có chuẩn như controllers, appsettings, startup, config cho các dịch vụ như log4net, class Attribute
Class thường => class kiểu để setup cho 1 thứ khác do ta định nghĩa. VD class chuyên lưu enum struct, class xử lý CreateMap để setup cho AutoMapper, class ánh xạ enum sang i18n. Class kiểu truyền thống, trong phạm vi nó được add reference, ta có thể khởi tạo với new và sử dụng các tính năng. VD class Repository khởi tạo new trong UnitOfWork, UnitOfWork khởi tạo new để sử dụng trong class Service được DI 



# Other
-> Header khác thường dùng:
Connection: 'keep-alive' => k đóng TCP connection mà tái sử dụng cho nhiều request sau. Thường kết hợp với header keep-alive.
'keep-alive': 'timeout=5, max=100' => nếu k có yêu cầu nào mới trong 5s sẽ đóng connection, connection này chỉ xử lý max 100 request là đóng

-> Có package google API convert text to speech

-> coveralls, travis CI, github CI/CD: test, deploy trực tiếp 
daemon: 1 package biến script thành chương trình dạng daemon. 




-> Nhược điểm của dedicated server là k thể horizontal scaling, buộc phải mua thêm server ở nơi khác để scaling.

-> VD mua 1 VPS trên digital ocean và chạy server. Bh muốn scale lên 2 server ở Sing và Mỹ. 
Các bước tối thiểu phải xử lý là:
Dùng load balancer phân phối tải, ghi log các thứ. 
Cấu hình DNS trỏ tới từng server hoặc trỏ tới 1 load balancer nếu dùng load balancer.
Xử lý fail over, 1 server sập sẽ đổ traffic vào server còn lại

-> Cách đơn giản hơn là dùng Cloudflare proxy làm load balancer. Nó có hàng trăm điểm phân phối toàn cầu, request tới nó trước rồi tự phân phối đến server gần nhất 
Nó cũng có sẵn cache.

-> Load balancer phân phối tải mà lại có 1 endpoint thì các request ở xa load balancer vẫn bị lâu như thường. Thực tế ta đang hiểu sai vai trò của load balancer. Nếu chỉ có vài khu vực, môi khu có 1 server thì chả cần LB làm gì. LB chỉ dùng khi 1 khu vực có nhiều server và cần route trong khu vực đó. Tức ta đã tăng số lượng server ở khu vực đó để nó chịu tải tốt hơn. 
Chứ ít server thì dùng DNS-based routing trỏ đến các server được đã là đủ r.

-> Nếu chỉ dùng 1 db duy nhất (ở sing) thì mọi request tới server ở Mỹ cũng cần gọi vào db ở sing để lấy bị lâu. 
Read replica => ghi ít thì ok vì chỉ có 1 db ghi ở xa sẽ lâu khi update. 
Chia độc lập customer => đảm bảo mọi user ở Mỹ sẽ kbh liên can đến data ở Sing. Nếu user đi từ Mỹ qua Sing thì query vẫn về Mỹ và bị lâu. 
Multi-master replica => đọc ghi đều nhanh nhưng cấu hình phức tạp. Phải có cơ chế fail over, cơ chế đồng bộ giữa mọi database, cơ chế xử lý conflict. VD dùng safe writes để đảm bảo dữ liệu ghi được xác nhận từ ít nhất 2 node trước khi commit.
Có thể dùng database proxy để điều hướng tới db gần nhất, két hợp cache.
=> Thường công ty lớn dùng kiểu chia customer độc lập chứ multi-master rất ít khi dùng. Vì đọc ghi nhanh từ mọi nơi trên thế giới mà update nhiều dễ conflict thì rất hiếm.


- Dự án k nặng thì deploy luôn database và server chung 1 VPS cho nhanh.



- Trong hệ thống lớn, khi nhiều service độc lập gọi lẫn nhau, mỗi log đến từ 1 request sẽ có cùng 1 traceId. 
TraceId duy nhất của 1 request giúp debug dễ hơn, thậm chí được duy trì dù gọi qua nhiều services khác nhau. 
Khi nhận 1 request và ghi log, sẽ lấy traceid được lưu trong request đó. Nếu k có mới tạo 1 Guid mới.

