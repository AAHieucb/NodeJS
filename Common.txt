# Tạo streaming server cho video
Thực tế với video, người ta có thể nhúng từ link youtube hoặc đăng lên ipfs hay cdn cloud thay vì dựng hẳn 1 server vì rất tốn, trừ các web chuyên về video.
Cơ chế: Người dùng click vào phần nào của video sẽ gửi http request nhận về 1 lượng bytes kể từ vị trí đó trở đi và tiếp tục cho đến hết video, thông tin này nằm trong header. Ở FE, video player của html5 hỗ trợ sẵn việc gửi request đi và xử lý response nhận về như nào rồi, server chỉ cần gửi lại đúng format response là được

-> Cơ chế tính lượt view cho video không phải là số lần gọi request GET và cũng k yêu cầu phải lấy xem hết mọi bytes của video. 
VD chọn 1 mốc 30s và chia khoảng 30s đó khắp video thay đổi vị trí random liên tục. Vd 10s đầu ở đoạn 1p->1p10s, 10s sau ở 2p->2p10s, 10s cuối ở 3p50s->4p => user phải xem đúng các đoạn đó mới +1 view. 

VD 1 giải pháp chống spam view là lưu IP user vào trong cache tự hết hạn và bị xóa sau khoảng 5p. Mỗi khi định tăng view bởi 1 ip sẽ check ip vẫn có trong database thì k cộng view lên. Tức là người dùng refresh liên tục trong 5p sẽ k có tác dụng vì ip vẫn có trong DB. Tức max 1 người trong 5p chỉ được 1 view
=> Thực ra lưu ip k ổn VD nhiều người cùng bắt VPN hay chung mạng LAN sẽ k chuẩn, ta có thể tạo 1 userid ảo dù chưa login và lưu 1 id vào cookies chứ kp lưu ip, mỗi request phải gửi kèm cookies lên để server lưu. 
VD các nghệ sĩ nổi tiếng khi cộng lượt view tăng quá nhanh, chắc chắn DB k thể sử dụng MySQL hay MongoDB mà phải sử dụng cache như redis.
Nên thêm ratelimit và black list chặn ip truy cập bất thường. VD 1 IP truy cập đồng thời tới cả nghìn lần 1p thì khá vô lý cho 1 mạng LAN thì sẽ bị chặn ngay. VD Dùng nginx làm reserve proxy có thể lấy được ip của user trong header trường X-Forwarded-For



# Dùng HTTP2 HTTP3
HTTP1 thì mỗi yêu cầu là 1 connection TCP riêng.

HTTP1.1 duy trì kết nối cho phép nhiều yêu cầu tới 1 server được xử lý trong cùng một kết nối TCP.
Nó còn có HTTP pipelining cho phép gửi nhiều request đồng thời trên cùng 1 TCP connection mà không cần chờ request trước done, nhưng response trả về phải đúng thứ tự. Head-of-Line Blocking là hiện tượng response request trước quá lâu làm cho các requests sau bị blocked, nên tính năng này ít được sử dụng.
Để đảm bảo k bị lỗi, browser duy trì nhiều TCP connection tới server và gửi song song, chứ k chỉ 1 connection.

HTTP2 dùng HTTP stream. Trong 1 TCP connection có thể gửi hàng loạt các stream request và các stream k cần đúng thứ tự nữa, giải quyết vấn đề Head-of-Line Blocking ở tầng application nhưng vẫn bị ở tầng transport với TCP: Client <--- 1 TCP connection [Stream1 header, stream2 header, stream1 data, stream3 header, ...] ---> Server
Server push new data tới client khi có update mà k cần client phải poll liên tục, giảm sô request. Dùng HPACK nén giảm kích thước header. Dùng binary format nhanh hơn so với định dạng văn bản của HTTP/1.x.

HTTP3 dùng protocol QUIC, dựa trên UDP ở ngay tầng transport nhưng nó chỉnh sửa để UDP mà tốt hơn TCP, vẫn có cơ chế phục hồi gói tin khi bị mất.
Client <--- 1 QUIC/UDP connection [Stream1, stream2, stream3, ...] ---> Server
QUIC cũng được dùng để đổi mạng trong điện thoại mà k bị lag vì dùng chung 1 connection id.

=> Mặc định server thường dùng HTTP1.1, phải cấu hình thêm nếu muốn dùng HTTP2 HTTP3. 
Cũng có thể dựng 1 proxy nginx server dùng HTTP2, khi đó sẽ k tận dụng hết dược sức mạnh của HTTP2: Client <-- HTTP2 --> Nginx <-- HTTP1.1 --> Server



# Bảo mật SSO và OAuth2
-> SSO: Đăng nhập 1 hệ thống, gửi token để truy cập được tất cả hệ thống con.
Nếu ta thấy hệ thống domain X mở rộng thêm 1 ứng dụng mới domain Y sao cho những ai đăng nhập X đều có thể đăng nhập Y thì dùng SSO. Tuy nhiên trình duyệt luôn tuân theo same origin policy. Tức domainX k thể truy cập cookie của domainY để tự động đăng nhập. Buộc phải thêm 1 central domain xử lý xác thực.

User vào bất cứ domain nào, nó đều redirect đến 1 authentication server để check thông tin đăng nhập:
Đã đăng nhập -> redirect về trang trước
Chưa đăng nhập -> phải đăng nhập -> lưu lại nếu là sessionid, không thì thôi -> gửi lại cho client lưu và redirect về trang trước -> session id có thể dùng để truy cập bất cứ app con nào trong phạm vi 1 session.

SSO có thể kết hợp OAuth2 để xác thực cho các app khác dùng data của mình. VD như OpenID Connect, Facebook Connect, SAML, Microsoft Account.

-> OAuth 2.0: đơn giản hơn OAuth 1.0
Custom thêm tính năng là ứng dụng bên ngoài có thể lấy thông tin người dùng trong ứng dụng gốc. VD game lấy thông tin danh sách bạn bè trên facebook để kết nối chẳng hạn. Cụ thể OAuth nó cho phép app truy cập thông tin mà chả cần đưa password vẫn xác thực được

VD: Client access Game, đăng nhập qua facebook
Chuyển hướng đến máy chủ xác thực facebook và login, cho phép Game dùng thông tin người dùng
Máy chủ xác thực của facebook chuyển hướng về url của Game (url này do người làm game đăng ký vào máy chủ xác thực của facebook), trả kèm id game + mật khẩu game + tham số mã
Người dùng trải nghiệm game bth
Game chạy nền bằng cách dùng id game + mật khẩu game + tham số mã để đăng nhập facebook dưới quyền người dùng
Máy chủ facebook trả về accesstoken
Game dùng accesstoken truy cập thông tin người dùng do facebook cung cấp

URL OAuth2 với discord: https://discordjs.guide/oauth2/#a-quick-example



# Bảo mật server thông dụng
-> Self sign: là trang web sẽ dùng SSL với chứng chỉ tự ký, chưa đăng ký với CA. 
Có thể dùng Let's script để có SSL free trong vài tháng. 
Dùng openssl để có key và cert tự ký: openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 => Sinh key và cert có hạn 365 ngày

-> CSRF (Cross site request forgery) là 1 vector đánh lừa trình duyệt thực hiện hành động không mong muốn trong ứng dụng người dùng đã đăng nhập.
VD: B là 1 người muốn phá hủy 1 dự án mà A đang làm. B đăng tải 1 bài lên diễn đàn www.webapp.com nhưng kèm theo 1 đoạn code kiểu: <img height="0" width="0" src="http://www.webapp.com/project/1/destroy">. A vào đăng nhập vào diễn đàn như thường lệ và xem bài viết của B. Khi đó, browser của A đã cố gắng load ảnh nhưng thực tế lại gửi câu lệnh destroy vào địa chỉ này để xóa project có id là 1. Access token hợp lệ vì người dùng đã đăng nhập. Chú ý là request có thể đến từ cùng trang web hoặc từ 1 trang web khác.
VD biến thể tinh vi hơn: hacker dùng 1 url rất mượt mà kiếu: <img height="0" width="0" src="http://www.ahackersite.com/abc.jpg"/> => xong cấu hình lại máy chủ: Redirect 302/abc.jpg http://www.webapp.com/project/1/destroy"/> thì người dùng k thể phát hiện ra được. Vấn đề này là phía người làm web cần phải xử lý.

--> Chặn bằng CRSF token trong form ẩn:
Trong mỗi phiên làm việc sinh ra duy nhất 1 crsftoken mới và FE cho vào form ẩn để gửi kèm. VD action gửi tiền:
<form action="http://bank.com/transfer.do" method="post">
  <input name="amount" value="100000"/>
  <input type="hidden" name="csrf_token" value="{{csrf_token}}">
  <button type="submit">Submit</button>
</form>
Khi thực hiện action, server check có csrftoken hợp lệ mới cho thực hiện là được. Hacker k biết giá trị trường này sẽ k thể CSRF được.

--> Chặn bằng SameSite option của cookie
SameSite là attribute của cookie quyết định việc gửi cookie cho cross site, ta cần đảm bảo request chỉ đến từ web của ta. Có 3 giá trị:
Strict: ngăn hoàn toàn việc gửi cookie trong mọi cross-site. Vd A đăng nhập rồi, xong vào website ở 1 link khác sẽ báo là chưa đăng nhập vì cookie k được gửi kèm
Lax: Tương tự nhưng vẫn gửi được cross-site với request GET, request POST sẽ bị chặn => mặc định 
None
=> Vượt qua Lax bằng cách pop up website và thực hiện. Khi ta thấy duyệt 1 site mà pop up lên 1 site khác và thông tin cá nhân bị đổi là hiểu vấn đề.

--> Double Submit Cookie: cách tốt nhất
Người dùng vào thì gửi 1 random val lưu vào cookie (tạo mới random) -> các form trong web sẽ có hidden field gắn giá trị random đó (k fix cứng) -> thực hiện request thì server check random val trong cookie với trong hidden field giống nhau là được.
WebA call tới API webB thì nên nhớ dù gửi lại có cookie của webB thì vẫn k đọc được cookie đó là gì nên k thêm đúng trường như frontend chuẩn được (or dùng header X-CSRF-Token)

--> Package csurf trong nodejs: tạo middleware chống crsf attack. Cơ chế nó gắn 1 token gửi tới client để client gửi lại r check thôi
Token csrf đảm bảo reset sau mỗi phiên dùng của user. Nếu là react phải cung 1 API lấy token về trước.

-> Dùng thư viện chống XSS: validator, xss, express-validator, xss-filter, DOMPurify. Bản chất nó sẽ validate regexp email, sanitize string, convert sang html entities.

-> SSL chống MITTM nhưng vẫn bị replica attack. 2 pp:
- Timestamp: VD ta cấm 1 request được lặp lại trong quá 1p bằng cách lưu dấu thời gian lại r check. Chú ý xử lý múi giờ khác nhau. 
Nhược điểm là vẫn replicate được trong 1p đó, an toàn hơn là dùng nonce
- Nonce: Cơ chế chống replicate attack. Client gửi request tới server thêm nonce cho server lưu và nếu 1 nonce từng được sử dụng sẽ lỗi luôn.
Có thể dùng sessionid nếu nó thay đổi ở mỗi request. Server nên lưu redis.

Để tránh redis phải lưu nonce quá tải thì dùng kèm cả 2 cách là tốt nhất. Vd: signature = md5(uid=1001&stime=19h00&nonce=sessionId-123456 + key)
Phía server: - Vẫn check timestamp chưa quá 1p
- Check nonce chưa có trong redis ok
- if(redis.hasKey('sessionid-123456')) { return false; } else { redis lưu lại nonce vói expire time là 1p }
=> Nhờ v sau 1p nonce bị xóa thì redis sẽ k tốn

-> Signature Generation: VD MITM bắt request chuyển tiền và sửa payload người nhận thành hacker. Điều này thực tế khó xảy ra vì các app quan trọng như ngân hàng, github thường gửi thẳng OTP về điện thoại, google authen. Giải pháp là ký payload bằng khóa của người dùng thì nếu hacker đổi payload sẽ k khớp với sig nữa. 
=> Cơ chế cặp khoá ở đây có thể làm như SSH key. 

-> BlackList: Cho người dùng hoặc IP nào spam vào blacklist cấm luôn, Vd khi 1 người dùng gửi quá nhiều request trong 10s liên tiếp. Có thể lưu vào redis chẳng hạn.
WhiteList: cấm mọi thứ trừ các IP và user trong whitelist

-> Server-Side Request Forgery (SSRF): Hacker khiến server gọi các request tới chính nó.
VD: Server có url http://localhost/admin cho người dùng input 1 url ảnh để nó fetch về. Hacker input luôn http://localhost/admin/delete, server lấy url về và thử fetch thì lại gọi hàm của chính nó. Do server tự gọi chính nó nên request thành công. 
Tức hacker có thể khiến server gọi API thực hiện hành động gì tuỳ ý nó, hoặc khiến server gọi vào API khác mà nó có quyền để lấy data nhạy cảm về. Cuối cùng trả ra FE hiển thị dưới dạng ảnh nhưng thực chất là hiển thị thông tin nhạy cảm cho hacker.



# JSON Hijacking
User vào web độc chứa mã: var script = document.createElement('script'); script.src = 'https://victim.com/data.json?callback=handleData'; document.body.appendChild(script); sẽ gửi request tới web đã đăng nhập fetch JSON data về. Fetch trực tiếp bị cản bởi SOP nên phải cho vào <script>
Fetch bằng script k lấy được kết quả trả về, giải pháp là in ra rồi overwrite hàm in là được. VD overwirte hàm get của Object:
var stolenData = {};
Object.defineProperty(stolenData, "user", {
  get: function() {
    alert('Đã lấy cắp dữ liệu: user'); // Gửi tới server của hacker
    return 'john_doe';
  }
});
Trình duyệt hiện đại đã fix điều này. VD ta tạo ra function Array đè lên JS được, nhưng sẽ k hoạt động với dấu [], mà chỉ được với new Array(1,2,3) k thể json hijacking.
Nhưng biến thể hiện đại đã cho phép overwrite mọi thứ với Proxy. VD: 
Object.setPrototypeOf(__proto__, new Proxy(__proto__, {
  has: function(target, name) {
    alert(name.replace(/./g, function(c) {
      c = c.charCodeAt(0);
      return String.fromCharCode(c >> 8, c & 0xff);
    }));
  }
}));

-> Cách chống: 
- Server cần dùng CORS, hoặc cấu hình CSP chuẩn nếu cho phép web khác gọi API, <script> qua mặt SOP nhưng k qua được CSP => nên giờ ít gặp kiểu tấn công này.
- Thêm for(;;;); vào đầu response, lúc xử lý thì lọc bỏ đi là được. Thêm bất cứ thứ gì miễn k thể parse JSON trực tiếp thành object là được.



# Bảo mật với SSH key
Kết hợp với tường lửa và firewall để bảo mật server cực mạnh
Vì dev thường không code thẳng trên server mà luôn phải truy cập vào bằng SSH bảo mật tốt hơn mật khẩu thông thường.

Cơ chế: Dev sinh cặp private và public key, gửi pubkey lưu ở server. Khi connect, server gửi 1 challenge tới client, client dùng pivkey mã hoá và gửi lại. Server dùng pubkey giải mã, nếu ra đúng message challenge cũ thì đúng.
=> Key lưu sẵn trong máy thì k cần gõ lại mk mỗi khi connect



# 3 cách connect db:
- K nên tạo 1 db connection global duy nhất dùng suốt dự án. Vì connection có thể đóng vì nhiều lý do mà ko biết như timeout hay lỗi mạng. Kể cả có setting reconnect hay sự kiện disconnect để gọi connect lại cũng k nên dùng
- Mỗi lần query sẽ khởi tạo connection và đóng ở cuối. Thường dùng cho các dự án lớn, query phức tạp.
- Connection pool là giải pháp tối ưu, query xong tự trả vào pool để tái sử dụng, setting config autoReconnect reconnectTries, tự đảm bảo connection k bị mất khi k sử dụng.
Néu server khởi động thành công mà connect db lỗi thì nên dừng ct, có thể throw error để dùng.



# Browser có sẵn cache
Cache browser phụ thuộc vào trường Cache-Control trong response header

- Header "Cache-Control" kiểm soát tài nguyên được cache như nào trong browser. Có thể kiểm soát có cache hay không, thời gian expires, lưu trữ cache trên proxy trung gian hay không => Nên set file css js ảnh là thời gian cực lâu, các api data đổi nhiều thì no-cache. 
Có thể tuỳ biến set cả cho FE (server host nó) hoặc set cho API server nodejs. Thực ra React host lên tự động cache các files tĩnh cần thiết mặc định rồi. Các proxy server như nginx apache thường luôn custom header này. Bth nếu k set thì mặc định dùng setting của browser, thg là no-cache Thường họ chỉ dùng Ca
- Header "Expires" trong response cũ hơn, nó xác định thời điểm cụ thể mà tài nguyên hết hạn trong cache.che-Control sẽ override bỏ qua trường Expires



# Hệ phân tán nhiều server thì query cái nào
Vấn đề muôn thuở của hệ phân tán: Khi dùng distributed cache, hoặc có nhiều api server và mỗi server dùng 1 cache riêng
Client query 1 server cache lưu có data rồi nhưng request sau query server khác không có phải get lại dẫn đến 1 data lưu ở nhiều server. Do đó nên dùng pp Hashing hoặc Sticky Sessions thay vì dùng Round Robin, Least Connections. Hashing sẽ hash thông tin client để lấy ra 1 server khiến cho mọi request của client luôn tới 1 server duy nhất.

Dùng Hashing gặp vấn đề khi server list biến động, lúc nào client cũng gọi vào server đó kể cả khi nó sập hay bị xoá rồi dẫn đến lỗi. Do đó họ dùng:
- Consistent Hashing: 
Dùng 1 hàm hash an toàn cho id của node và id của data record. Ra 1 giá trị thì nhét vào 1 vòng tròn. Mỗi key sẽ gắn với node gần nhất kề nó theo chiều kim. Vd:
0 ---- A ---- key1 ---- B ---- key2 ---- E ---- key3 ---- C ---- key4 ---- D ---- 2^32-1
Key 1 gắn node B, key 2 gắn node E. Nếu ngừoi dùng muốn query data có key 4 thì họ query vào cache server D. Thêm xoá server không sợ lỗi mà lại nhanh.
- Rendezvous Hashing: 
Muốn tìm node nào lưu record hiện tại, ta tính weight của data với từng node: weight(key, node) = hash(key of record + node_id) => Node có giá trị cao nhất sẽ lưu record đó.



# Other
-> Header khác thường dùng:
Connection: 'keep-alive' => k đóng TCP connection mà tái sử dụng cho nhiều request sau. Thường kết hợp với header keep-alive.
'keep-alive': 'timeout=5, max=100' => nếu k có yêu cầu nào mới trong 5s sẽ đóng connection, connection này chỉ xử lý max 100 request là đóng

-> Có package google API convert text to speech

-> coveralls, travis CI, github CI/CD: test, deploy trực tiếp 
daemon: 1 package biến script thành chương trình dạng daemon. 
