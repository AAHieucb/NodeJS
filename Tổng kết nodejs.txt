# NodeJS
-> Để update nvm lên version mới, phải tải lại từ github về file setup.exe và chạy mới lại

-> node cli: 
node -> http.STATUS_CODES / Date.now()
node --watch => dùng thực tế cho development => ref tới "BlogWebBE"
node --run => thay thế hoàn toàn npm run, nhanh hơn tẹo



# Dùng typescript trong nodejs
BE viết bằng JS mà lại dùng package viết bằng typescript được là vì package luôn được compile thành js sẵn rồi.
Check reference package hiện file typescript là vì npm vẫn giữ code typescript của nó thôi.

-> Cách dùng:
Trong môi trường dev, cài ts-node là 1 package giúp chạy trực tiếp file typescript với lệnh "ts-node index.ts". Cơ chế nó build typescript trong quá trình chạy nên tốc độ chậm và k dùng cho production 
Trong production, cài package "typescript" cung lệnh tsc. Viết file tsconfig.json để setup config. Trước khi start server, phải chạy lệnh "npx tsc" để biên dịch index.ts thành index.js trước r chạy như bth "node index.js"



# Master require, import, module.export và export, dynamic import
Cần tránh circular dependencies

-> Cơ chế là object được module.exports sẽ chỉ chạy qua 1 lần rồi lưu cache, tức object dùng như 1 singleton.
Khi dùng async để khởi tạo biến, logic chạy như bth, require như bth, hàm chạy xong sẽ dùng được biến thôi.

VD1: const x = new Class(); 
module.exports = x; hoặc module exports = { x }; hoặc module.exports = { x: new Class() };
VD2: Class { static method() {} }
module.exports = Class; 
const Class = require("./Class"); Class.method();
=> Object là singleton chỉ khởi tạo 1 lần.

VD3: module.exports = () => new Class(); 
const createInstance = require("./Class"); const x = createInstance();
VD4: module.exports = Class;
const Class = require("./Class"); const x = new Class();
=> Mỗi lần dùng là 1 lần new Class được tạo mới

VD5: class MyClass { 
  constructor() { this.initialize(); } 
  async initialize() { } 
  static getInstance() { 
    if(!MyClass.instance) MyClass.instance = new MyClass();  
    return MyClass.instance; 
  } 
}
const instance = Database.getInstance();
module.exports = instance;
const instance = require('./file');
=> Khởi tạo bằng hàm async và lấy singleton export ra dùng. Đảm bảo initialize async hoàn thành mới dùng biến là được => best practice

->*** Bản chất lỗi async: gọi hàm async, bên trong hàm gán giá trị cho 1 biến và k chờ nó, sau đó ta export biến ra sẽ lỗi vì khi export, nó sẽ copy state hiện tại của biến vào cache (khi chưa thực hiện xong await) và bị sai => nói chung là như copy constructor
VD: let x = 1; async function runSleep() { await sleep(2000); x = 2; } runSleep(); module.exports = { x };

Ta nghĩ là object export ra sẽ bị copy vào cache. Nhưng là copy địa chỉ, chứ giá trị 1 trường mà đổi async thì vẫn thấy bth thôi. 
Ta có thể fix bằng cách export 1 hàm trong file trả về biến đó thì hàm bị copy cache, còn biến vẫn chạy và k bị xoá do hàm vẫn gọi tới. 
VD: let x = 1; async function runSleep() { await sleep(2000); x = 2; } function getX(){ return x; } runSleep(); module.exports = { getX: getX };
Ta có thể wrap nó vào 1 biến khác thì biến bao ngoài bị copy, vẫn trỏ tới trường bên trong k bị copy thôi 
VD: let client = {}; client.x = x; module.exports = client; => sẽ cache client copy ngay, vùng nhớ x vẫn có ref tới nên k bị xóa, async chạy xong là dùng bth thôi.

-> Nhanh:
- Biến module.exports + require nhiều lần luôn là singleton và sẽ copy vùng nhớ, nên đổi 1 trường trong hàm async thì ok chứ gán = 1 vùng nhớ khác sẽ k hoạt động.
- Dùng dynamic import với await import("") có thể giúp dùng module ESM trong commonjs vì k dùng được require. Dùng vì lazy load.



# Dùng biến môi trường
Chỉ dùng .env nếu cần lưu thông tin nhạy cảm, nếu k thì file config là đủ rồi vì config thậm chí lưu được nhiều kiểu data phức tạp hơn là chỉ string.

-> 3 cách:
Dùng "node --env-file=.env server.js" => k cài thêm package, xác định .env file cần lấy ngay trong command để chia môi trường => best practice
Dùng dotenv để lấy data từ file .env => thêm require("dotenv").config(); sẽ mặc định lấy .env, có thể chỉnh lấy rõ file .env nào trong code
Dùng "cross-env NODE_ENV=pro node server.js" => lấy trực tiếp process.env.NODE_ENV, cái này đè lên file .env

--> Phải có "npm install --save-dev cross-env" để dùng trực tiếp tham số trong câu lệnh chạy được với mọi OS. Vì mặc định nó chỉ chạy được với linux và macos thôi, mở dự án trên máy win sẽ k chạy.

--> Dùng dotenv kết hợp dotenv-expand còn giúp tạo biến môi trường mà dựa trên biến môi trường khác
VD dotnev kết hợp cross-env để chọn .env file ngay trong command:
require('dotenv').config({
  path: `.env.${process.env.NODE_ENV}`
});



# Toàn bộ multithread, multiprocess, worker thread
-> PM2 chạy nhiều instance của server. PM2 tự phân bố mỗi process trên 1 CPU core để tối ưu. Nếu máy chỉ có 1 cores, việc chạy nhiều instance với PM2 sẽ k có ích gì. Default dùng round robin để phân bố request vào các instances. Auto restart khi server crash, kiểm soát resource, live reload với --watch, xem log.
Dự án chạy với PM2 thì nên cài vào package.json, còn tự cài global để xem quản lý log các thứ nếu cần thôi. Dùng được với FE nhưng chỉ cần dùng với BE thôi.
Cơ chế tạo ra 1 process master quản lý các process worker, các worker cùng listen trên 1 port.

PM2 có 2 chế độ là forkmode và cluster mode:
- Fork mode: "pm2 start app.js --name my-api" => lệnh chạy 1 instance duy nhất. Muốn chạy nhiều instance thì phải chạy nhiều lần script đó. Mỗi instance là độc lập và OS tự kiểm soát việc phân bổ vào CPU core nào, có thể là cùng cores.
- Cluster mode: "pm2 start app.js -i 0" => PM2 sẽ tự phân bổ instance vào các cores khác nhau theo round robin => luôn dùng

--> Tổng kết lệnh:
pm2 start app.js => k tham số sẽ mặc định chạy 1 tiến trình duy nhất
  -f => force chạy, khởi động lại tiến trình file đó nếu có đang chạy
  --name appname
  --max-memory-restart 100M => 1 instance dùng max 100MB mem, nếu quá sẽ tự restart lại
  -i max => max là dùng max số process = số core trong máy, hoặc 1 số gì đó chỉ định số lượng instance.
  --watch => restart các instance khi code change
  --node-args='--env-file=.env' => thêm params cho lệnh chạy nodejs
  --no-daemon => k chạy trong background nữa. Khi dùng với docker thì nên có vì nếu chạy bth thì docker dừng luôn vì nó tưởng tiến trình đã kết thúc.
pm2 start ecosystem.config.js => chạy theo config
  -only name1 => chỉ chạy app tên là name1 theo file config
  -only "name1,name2,name3" => chạy 3 app theo file config
  --env production => chạy theo env "production"
pm2 stop appname => or id, or all
pm2 restart appname/id/app.js
pm2 delete appname
pm2 show appname => xem chi tiết app
pm2 list => list các app đang chạy
pm2 logs => xem log mọi apps
pm2 logs appname => xem log cụ thể 1 app
pm2 monit => Giao diện giám sát realtime (CPU, RAM,...)
pm2 flush => xoá mọi log
pm2 delete all => xoá mọi app

VD PM2 để chia môi trường production và development:
module.exports = {
  apps: [
    {
      name: 'my-app',
      script: 'app.js',
      watch: true,
      env_production: { // Dùng env var khi chạy với pm2 start ecosystem.config.js --env production
        NODE_ENV: 'production'
      },
      env_development: { // Dùng env var khi chạy với pm2 start ecosystem.config.js --env development
        NODE_ENV: 'development'
      }
    }
  ]
};

--> Tự chạy server khi máy khởi động lại với "startup"
pm2 startup => hiển thị câu lệnh sudo và chạy câu lệnh đó để setup pm2 với systemd
pm2 save => lưu danh sách app hiện tại đang có 
Từ giờ mỗi khi khởi động lại máy sẽ tự chạy pm2. Mỗi khi xoá hay thêm app cần chạy lại pm2 save để cập nhật list app chạy startup lại cùng hệ thống.
pm2 unstartup => tắt tính năng

-> Dùng os: Chrome V8 là 1 js engine dùng libuv viết bằng C++ để tương tác với phần cứng và thực hiện các task nặng.
Khi dùng hàm sync thì nodejs sẽ khoá event loop. Còn hàm async vẫn tự chuyển sang thread pool thread pool nhờ libuv để chạy nền cho nhanh. Khi dùng await, nó đợi nhưng thực tế main thread vẫn chạy event loop các task khác, khi libuv xử lý task nặng xong sẽ trả về callback vào event loop xử lý đoạn code dưới await.
Biến môi trường process.env.UV_THREADPOOL_SIZE thiết lập kích thước threadpool mà libuv tự sử dụng cho các tác vụ async và I/O. Thường ta k cần sửa mà để default là 4, trừ khi server có nhiều task nặng chạy và máy có nhiều cores hơn bth.
URL bản chất libuv và threadpool để nodejs single thread xử lý được task nặng: https://www.youtube.com/watch?v=Vej327jN8WI

Phân biệt PM2 chia ra nhiều process, mỗi process là 1 cores do OS phân bổ. Còn UV_THREADPOOL_SIZE là số lượng thread, 1 core có thể chạy nhiều thread, tức số thread > số core thì các thread sẽ cạnh tranh để dùng CPU core.

--> Có 2 loại, 1 là các task I/O bound thực sự như đọc file, call api, query db. Hoặc các hàm là CPU bound nhưng nodejs đẩy vào threadpool của libuv để k chặn event loop thì nó giống như I/O bound. 
VD logic hash nặng là CPU bound mà ta dùng như I/O bound bằng cách cho vào thread pool. Nếu tăng UV_THREADPOOL_SIZE thì ta sẽ cho phép nhiều tác vụ hash chạy song song hơn.

=>*** Khi dùng kết hợp PM2 và UV_THREADPOOL_SIZE thì nên set tổng threads (PM2 process × UV_THREADPOOL_SIZE) nên ≤ (số core × 2) để tránh quá tải. 
Nếu I/O bound nhiều thì PM2 để là 2 instance và UV_THREADPOOL_SIZE min là 4. Nếu CPU bound nhiều thì PM2 để là 4 instance và UV_THREADPOOL_SIZE min là 2.
Cụ thể CPU bound nhiều thì PM2 instance nên cao, đó là khi xử lý logic trên dữ liệu lớn, tính toán số, xử lý json synchronouse, thuật toán nặng như xử lý ảnh. I/O bound nhiều như truy vấn DB, đọc file, mã hoá async thì nên set UV_THREADPOOL_SIZE cao. 
Phải set UV_THREADPOOL_SIZE trước khi server chạy mới có tác dụng. VD set trong .env và dùng dotenv sẽ k được vì app chạy rồi mới load. Phải dùng inline hoặc --env-file.

-> worker_threads là module có sẵn trong nodejs giúp custom dùng libuv.
Mặc định libuv chỉ dùng cho các task như DNS lookup, đọc file, I/O, mã hoá. Các task nặng ta tự tạo, VD tính tổng từ 1 tới 1 tỷ, là hàm sync sẽ block mainthread. worker_threads giúp custom chạy hàm đó trên thread riêng bằng libuv.
Libuv bth luôn an toàn và k sợ data race vì data trong các thread luôn độc lập, dùng worker_threads cũng vậy. Chỉ vài case hiếm dùng với SharedArrayBuffer có bị data race.

-> Nhanh: 
Dùng PM2 kết hợp set process.env.UV_THREADPOOL_SIZE trước khi chạy app.
Dùng worker_threads nếu có task riêng thực sự nặng muốn chạy hoàn toàn độc lập trên worker_threads



# Server tránh xung đột biến global
Khi làm việc với C# ASP.NET, mỗi client là 1 thread riêng nên mỗi request sẽ dùng biến độc lập trong từng thread. Ta vẫn có thể tạo class singleton dùng chung được. Xong ta còn phải xử lý các biến khi vào các async context chạy song song thì dùng chung giá trị hay độc lập.
Trong nodejs là single thread và dù nhiều request đến mấy cũng chạy lần lượt và asynchronous nhau. Tức dù k bị conflict write biến đồng thời thì các request vẫn có thể dùng chung biến của nhau loạn xạ dẫn đến kết quả k mong muốn. Thông thường ta tạo biến local cho từng request nên k sợ bị xung đột, hiếm khi dùng biến global.

Module "async" đảm bảo chỉ 1 luồng có thể truy cập và sửa biến global cùng một thời điểm. Cơ chế là add đoạn mã và 1 queue thực hiện lần lượt.
VD: const async = require('async');
let globalVariable = 0; // Khai báo biến global
const lock = async.queue(
  async (task, done) => { 
    try { // Đoạn mã trong này chỉ được thực thi bởi một yêu cầu tại một thời điểm
      const newValue = await performSomeOperation(task.value);
      globalVariable = newValue;
      done();
    } catch (error) {
      done(error);
    }
  }
);
function performSomeOperation(value) { // Hàm side effect
  return new Promise((resolve) => {
    setTimeout(() => {
      const result = globalVariable + value;
      resolve(result);
    }, 1000); // Giả định thời gian chậm trễ 1 giây
  });
}
function yourApiEndpoint(req, res) { // VD hàm gọi ở API endpoint
  const valueFromClient = req.body.value;
  lock.push({ value: valueFromClient }, (error) => { // Thêm yêu cầu vào hàng đợi để có đồng bộ
    if (error) {
      return res.status(500).json({ error: 'Đã xảy ra lỗi trong quá trình xử lý yêu cầu.' });
    }
    return res.status(200).json({ message: 'Yêu cầu đã được xử lý thành công.' });
  });
}
=> Dùng `async.queue` để tạo một hàng đợi đồng bộ hóa. Hàm đưa vào hàng đợi sẽ kbh thực hiện song song.



# Built-in module trong nodejs
URL tổng hợp: https://www.w3schools.com/nodejs/ref_modules.asp

-> Dùng crypto: dùng scrypt hash tốt hơn bcrypt. Dùng random salt để cùng password mà khác hash, lúc verify k cần truyền lại salt.

-> Dùng child_process: hỗ trợ thao tác đa luồng trong nodejs. Dùng process.send trong nodejs có thể gửi data từ process con sang process cha.
--> Dùng spawn: chạy 1 lệnh nào trên 1 tiến trình con và trả ra cho stdio
--> Dùng exec: chạy lệnh nào trên 1 tiến trình con và bắt sự kiện
--> Dùng execFile: chạy lệnh nào trên 1 tiến trình con và trả ra cho buffer
--> Dùng fork: gọi fork 1 phát là file đó được thực hiện luôn trên 1 tiến trình riêng



# Các package backend NodeJS thường dùng
-> yargs: xử lý tham số từ dòng lệnh cmd. Kết hợp minimist để parse process.argv thoải mái
-> node-persist: giúp tạo 1 global store tạm, tắt là mất.
-> cheerio: thư viện giúp parse DOM, tạo web crawler
-> puppeteer: tự động thao tác trình duyệt bằng cách điều khiển các action trên Chrome
-> module-alias: import module relative url gọn
-> Joi: thư viện validate type của object, email, password, not null => ref tới "Projects / BlogWeb"
-> hcaptcha: tạo captcha
-> KvJS: thư viện giống redis nhưng là dùng với biến JS bth
-> slugify: biến string thành chuỗi slug dùng trong url

-> node-cache*: cache trong nodejs bằng biến local. Cần chú ý api nào update data thì phải stale cache đó. 
Nếu data update nhiều thì k cần dùng cache
Nếu data update ít hoặc k yêu cầu realtime quá mà query nhiều thì nên dùng.

-> chalk: package giúp style text trên console
figlet: package in chữ khổng lồ trên console
marked + marked-terminal: vẽ ngôn ngữ markdown lên terminal, có thể dùng kết hợp với chalk để custom style => chả bh dùng
=> Thường chỉ dùng khi cần tạo thư viện

-> helmet: tự thêm các header bảo mật cần thiết. Khi dùng thì 1s số lượng request có thể xử lý bị giảm đi vài nghìn, đánh đổi security và performance
-> http-status: thao tác với các loại status http
-> validator: giúp santinize string để chống XSS. Vd giúp check có phải email hay không chẳng hạn, tập hợp các type check có sẵn
-> concurrently*: khi cần chạy song song client và server trong 1 dự án cùng lúc chỉ bằng 1 lệnh
-> @apollo/server + graphql: để xây 1 graphql server. Kinh nghiệm tạo graphql server thì cái gì cần phân trang thì buộc phải là 1 entity riêng
-> telegraf / node-telegram-bot-api: giúp tương tác với telegram, tạo bot tự động nhắn tin vào channel thay thế email. Cần api key của tele.
-> bullmq*: giúp tạo queue, lập lịch chạy cron job, thay thế node-cron và node-schedule
-> @google-cloud/text-to-speech
-> commander: xây ứng dụng dòng lệnh, custom chạy lệnh nào thì thực hiện actions là gì

-> node-mocks-http: mock http api 
-> supertest: test nhanh http. Hoạt động với mọi test framework or test 1 mình k cùng framework nào cũng đươc
-> Autocannon: autocannon -c <> -p <> -d <> <url> 
-c là số lượng connection đồng thời, mặc định là 10 user cùng lúc
-p là đóng gói, bnh gói requests thì mặc định là 1
-d là số giây nó phản hồi lại, mặc định là 10
VD: autocannon http://localhost:5000/ thì sẽ check 1 gói 10 user chạy cùng lúc trong 10 giây thì mỗi giây có bnh request xử lý được thành công



# Dựng server optimize image
-> Dùng ImageKit hoặc Cloudinary đều cho optimize image và video realtime. Nó tự dùng CDN và cung blur image chuẩn

-> Sharp: giúp dựng server optimize image cho nodejs. Input ảnh và lấy ra đủ loại kích thước muốn blur hay chất lượng giảm như nào tuỳ

-> Combo https://github.com/MobileTeleSystems/image-optimize hỗ trợ tận răng chỉ cần chạy với docker là được
Có thể kết hợp với @mts-pjsc/image-optimize dùng ở FE 



# Tạo timeout cho API
-> Dùng lib connect-timeout: cung middleware timeout. Cơ chế là setTimeout sau 1 ktg đó thì send error và bắt sự kiện request close thì clearTimeout thôi

-> Tự implement middleware timeout trong express:
function withTimeout(ms) {
  return (req, res, next) => {
    const timeout = setTimeout(() => {
      if (!res.headersSent) { // header của response đã được gửi đi hay chưa
        res.status(503).json({ error: `Request timeout after ${ms}ms` });
      }
    }, ms);
    res.on('finish', () => clearTimeout(timeout));
    res.on('close', () => clearTimeout(timeout));
    next();
  };
}
app.get('/only-this-route', withTimeout(5000), async (req, res) => {
  await new Promise(r => setTimeout(r, 6000));
  res.send('...');
});

-> Timeout global mọi request của server express
server = app.listen(...)
server.setTimeout(10000, () => {
  console.log("Server handling request over timeout");
});

-> Timeout cụ thể trong 1 API:
app.get("/slow", (req, res) => {
  res.setTimeout(5000, () => {
    console.log("Response timed out!");
    res.status(503).send("Request took too long");
  });
});



# Thao tác với file
Luôn dùng stream cho file
Chỉ dùng buffer khi cần binary data từ file hay mạng, không phải chuỗi văn bản bth. NodeJS dùng 1 buffer pool chứa các buffer k còn được sử dụng. Khi cần buffer sẽ lấy từ pool ra, nếu k có mới tạo mới 1 biến buffer khác. VD Buffer.allocUnsafeSlow(<size>) để dùng 1 buffer lâu dài k cần quản lý bởi pool và gc

-> Dùng fs: Thao tác với file => ***Điều đặc biệt là nó có thể watch sự thay đổi của 1 file, điều mà database k làm được
Lib rimraf: thư viện hỗ trợ xóa file và thư mục tương thích mọi hđh
Lib mv: move file tới bất cứ đâu. Mạnh hơn fs vì fs bị giới hạn bởi quyền, bản chất là nó xoá file vị trí cũ và create new file ở vị trí mới

-> Upload file lên server
- formidable: Xử lý files upload từ client. Phức tạp, tốc độ cao, chiếm ít bộ nhớ, bị hạn chế tính năng
- express-formidable: thay thế cho formidable khi dùng trong express => bỏ
- multer*: cung cấp đầy đủ options và tính năng, code đơn giản

FE nên gửi ảnh qua FormData, tương đương với <form action="/action_page_binary.asp" method="post" enctype="multipart/form-data"> trong html thuần.
Để tránh DDoS upload file:
- Chỉ user đã authen mới được đăng ảnh với rate limit và size limit xác định
- Dùng lib clamscan: scan virus trước khi upload
- Dùng bên thứ 3 lưu trữ file như S3, cloudinary



# Dùng stream
Bản chất việc chia chunk stream cũng như chia batch list data, là để xử lý từng phần và giải phóng bộ nhớ trước khi xử lý phần sau, giúp tiết kiệm bộ nhớ hoặc đỡ nặng khi call api. Chứ nếu chia batch xong vẫn lấy tất cả thì chả có ý nghĩa gì.
Với các file lớn, dùng stream giúp tối ưu bộ nhớ gấp trăm lần và tốc độ cũng nhanh hơn, k bị tràn buffer => nên dùng stream mọi lúc, trừ khi có nhu cầu xử lý toàn bộ file 1 lúc
VD đọc 1 file và ghi vào 1 file khác, fs.readFile(..., (err,data) => { fs.writeFile(...) }) nên thay thế bằng: (fs.createReadStream(...)).pipe(fs.createWriteStream(...));
VD xem memory của 1 process nodejs trong win: chạy server -> vào Task Manager tab Details -> tìm process tên là "node". Mỗi request sẽ thấy memory tiêu thụ tăng lên để xử lý 

-> Mỗi stream trong nodejs đều là 1 event emitter cho phép bắt sự kiện. 4 sự kiện có sẵn là data(đọc), end(hết dữ liệu để đọc), error, finish(khi hoàn thành)
Các stream trong NodeJS đều là chuỗi or buffer. Chuyển sang chế độ object mode của stream giúp nó thao tác với các kiểu giá trị khác của JS k là dạng buffer hay chuỗi



# Dùng ExpressJS
Chỉ giúp tạo server dễ hơn chứ mọi lang đều có cách chạy server thuần.

-> Dùng middleware: khi có request thì các middleware chung k xđ url ưu tiên chạy trước rồi mới đến các middleware riêng của url đó
1 middleware có thể truyền dữ liệu vào req cho middleware tiếp theo lấy. Các middleware có sẵn đều tự gọi next(), chỉ có middleware ta tự tạo mới phải gọi next thủ công
Bắt lỗi kết hợp với middleware error handler 4 tham số và app.all("*", (req,res,next) => {<>}) khi gọi route k tồn tại
Có express.Router giúp chia 1 route ra thành nhiều route con

-> Dùng view engine xây web ssr với pug, thay cho ejs cú pháp khó dùng

-> app.set("trust proxy", true); => khi server nằm sau 1 proxy và cần lấy ip của user thì bth chỉ lấy được ip của proxy, muốn lấy ip user phải báo cho express biết. 
true là tin tưởng mọi proxy, false k tin tuỏng.
app.set("trust proxy", 5); => tin tưởng 5 proxy gần nhất
app.set("trust proxy", '127.0.0.1, 192.168.0.1, 192.168.0.2'); => tin 3 proxy có ip cụ thể
=> Khi đó server có thể lấy ip thực từ header x-forwarded-for



# Nén data truyền qua API
Nhiều nền tảng như Cloudflare cũng hỗ trợ sẵn nén data: Client <---10KB--- Cloudflare <---100KB--- Origin server

compression: lib nén giảm lượng dữ liệu cần truyền qua mạng với gzip. Lưu ý tốc độ nhanh hơn nhưng tăng áp lực lên CPU => nên dùng mọi lúc trừ khi CPU server yếu
shrink-ray-current*: dùng thuật toán brotli mới của google còn giúp nén mạnh hơn nữa => best practice, éo được với v23



# Dùng cors
Same Origin Policy (SOP) tự có sẵn trên browser mặc địnhcản mọi truy vấn khác domain để tăng tính bảo mật cho website.

-> Bản chất cors: Vào 1 website, mở F12 và fetch API thì origin là website đó. Nếu gõ url vào browser, dùng postman, call từ server thì origin là undefined.

--> Các cấp độ để cấu hình cors:
- Nếu ta k cấu hình cors thì mặc định nó dùng SOP, ta k thể truy vấn từ mọi origin website khác nhưng lại có thể truy vấn từ origin undefined or vào trang web của nó để tự call đến chính nó.
Developer có thể disabled security mode trên trình duyệt or dùng các extension cho phép trình duyệt tự động có các header Allow-Access-Origin với các request là được.
- Nếu ta cấu hình cors cho phía server có thể tùy biến cho phép origin xác định truy cập API, hoặc truyền 1 function check origin tùy biến. VD: facebook dùng cors cho chính nó và cũng allow call từ origin undefined vì app messenger cũng call api được.

-> Để dùng cors có thể dùng lib cors.
Hoặc tự set 3 headers:
Access-Control-Allow-Origin là url nào được gọi vào server
Access-Control-Allow-Credentials để là true thì được phép dùng cookies trong các request cors
Access-Control-Expose-Headers: Header1, Header2 => cross-origin khi client nhận về ngoài các header mặc định, còn lấy được các header nào thì truyền vào. Để * là tất cả.



# Dùng socketio
Cơ chế Socket.io xây dựa trên Engine.io. Đầu tiên chạy long-polling để tạo kết nối, rồi dùng websocket để truyền tin.
Có thể bắt sự kiện giữa socket client và server, broadcast event, tạo kênh và phòng, tự động kết nối lại, phát hiện ngắn kết nối, tạo channel nén dữ liệu khi gửi.

VD: socket.volatile.emit("event_name", data); => volatile thì socket sẽ không cần đảm bảo rằng tin nhắn đã được nhận, giúp giảm độ trễ, gửi là xong luôn. Nếu dùng nó thì đang gửi mà disconnect thì bỏ luôn, còn nếu k dùng thì message được lưu lại tạm thời và khi reconnect sẽ gửi lại.

Socket đắt nên ta thường tối ưu kiểu tạo phòng như battle hand, thay vì connect luôn, nếu k vào phòng thì chưa cần kết nối socket. Nên cho options user enable chứ k luôn tạo socket mỗi khi vào web. Khi tắt client sẽ tự disconnect socket nên k cần handle gì thêm
Cách tốt nhất là code theo luồng. VD tưởng tượng tạo phòng, rồi mn vào thì có data rồi làm gì thì có data gì, ta sẽ dễ dàng biết cái nào phát sự kiện và làm gì. VD lúc connect thì phát sự kiện nhận về data 
Phía client hay server đều có thể tách file riêng cho export ra cái socket để thao tác, cô lập module. VD cần gửi data cho 1 list socket thoả mãn đk: tạo singleton lưu list socket export từ file riêng; trong hàm on cũng có thể lấy list socket với io.sockets.sockets => ref tới project "Battlehand"
Phải setup cors cho socketio để cho phép client connect tới, tránh để người ngoài connect vào

-> Bản chất khi gọi io.connect():
Client call tới server qua 1 dạng. VD: ?EIO=3&transport=polling&t=LqtOnHh
Server trả lại với: "90:0{"sid":"pcJM_AEZirrJT-DuAAUy","upgrades[], "pingInterval":3600000,"pingTimeout":3600000}2:40" => tức server tạo ra 1 socket object cho từng client và trả lại id của socket object đó. 
Sau đó client call tiếp tới server connect tới cái socket client có id đó: ?EIO=3&transport=polling&t=LqtR6Rn&sid=0JFGcEFNdrS-XBZeAAXM => đây là long poll call và là connect thực sự

-> Polling: query liên tục xem có thay đổi không. Duration càng ngắn, càng tốn tài nguyên.
Long-polling khắc phục nhược điểm của polling với ý tưởng: client gửi 1 request và server giữ lại request đó và sẽ response khi có 1 sự kiện tương ứng diễn ra. Nếu request client bị timeout, khi hết timeout nhưng vẫn chưa có sự kiện mong đợi nào thì server buộc trả về 1 response mà chả có dữ liệu nào, vẫn tốt hơn short-polling nhiều rồi.
Để tránh việc client bị treo hay ảnh hưởng hiệu suất của tác vụ khác, khi sử dụng long polling, nên thực hiện long polling trên một thread riêng => ít dùng

-> URL: https://socket.io/docs/v4/tutorial/step-7 => Đb là nó dùng serverOffset để đánh dấu sẽ gửi message thiếu bù lại khi bị disconnect rồi reconnect.

-> Fix lỗi socket client để lâu tự bị disconnect, lúc bật lên sẽ lỗi. Phải thêm config để tránh lỗi:
const socket = io(BASE_URL, {
  path: "/socket.io", // default 
  transports: ["websocket"], // xđ transport mechanism dùng cho connection như websocket, polling. Ở đây dùng để "websocket" để duy trì socket lâu dài.
  secure: true, // Báo dùng connect secure ở đây là wss. Nếu dùng ws thì chỉ connect 1 lúc r tự báo lỗi vì đường truyền k được mã hóa sẽ nguy hiểm
  reconnection: true,
});
Nếu có authentication khi truyền sẽ phải thêm token để server check quyền với "query":"token="+Auth.getToken()



# Session và cookie
Server k thể xác định được requests HTTP có phải từ cùng 1 người hay không vì HTTP là 1 giao thức k trạng thái, cookie ra đời đã giải quyết vấn đề đó. Cookie giới hạn bộ nhớ nhỏ, lưu và truyền data giữa client server. Tùy biến lưu lâu dài hay ngắn hạn.
Session là data trao đổi giữa client và server, tắt browser bật lại là mất.

Session storage là khái niệm chỉ ở browser, có thể dùng lưu session data. 
Session cookie là việc cố tính lưu session data vào cookie thôi, vẫn tùy biến tắt browser bật lại là mất.

-> Lưu session data:
- Có thể dùng express-session lưu data trong cookie ở browser, server ký data để đảm bảo k bị đổi bởi client chứ server k cần lưu => best practice
- Có thể tùy biến session data lưu lâu dài hay ngắn hạn ở cả client và server:
Client lưu trong localStorage, sessionStorage
Server lưu trong redis, mongodb

VD redis có store: new RedisStore(),
VD connect-mongo hỗ trợ lưu session data:
store: new MongoStore ({ 
  url: 'mongodb: // localhost: 27017 / test-app', // URL MONGODB CỦA BẠN 
  ttl: 14 * 24 * 60 * 60, // thời gian hết hạn 1 session
  autoRemove: 'native' 
}), => Đăng nhập vào mongo atlas sẽ thấy session được lưu ở đó

--> Pb lib:
cookie-parser: giúp đọc và lưu cooke tùy ý
express-session: dùng cookie lưu session data cho expressjs. Cứ set là có thêm req.session tùy ý get và set data ở server, bản chất nó lưu vào cookie và sign với secret, chỉ tồn tại trong 1 sessio.
Còn có cookie-session lưu session data trong cookie nhưng k bị giới hạn ở express server.
=> Nếu chỉ cần cookie lưu session thì dùng express-session, còn không thì cookie-parser tùy ý lưu được session hoặc permanent mà.

-> Giải pháp sync session data trong hệ phân tán: client gửi request tới nhiều server khác nhau, server 1 lưu session data, server 2 k lưu sẽ invalid yêu cầu login lại
- Lưu session data chỉ ở client thông qua cookies / localStorage
- Lưu ở local server thì cấu hình nginx trung gian thuật toán chỉ gửi 1 user tới 1 server là được
- Lưu ở 1 database or redis chung để nhiều server cùng lấy được, thường dùng cho SSO, nhược điểm là sập phát toang luôn
- Lưu ở local 1 server, rồi gọi đồng bộ copy session data vào các server khác => éo ổn



# Dùng nodemailer
-> Gửi mail với gmail thì khi gửi đi sẽ bị chặn, nodemailer để chạy được thì: 
- Với tài khoản bth: ta phải bật quyền truy cập của ứng dụng kém an toàn của google account trong mục bảo mật
- Với tài khoản xác minh 2 lớp (vd qua số đt nx): bảo mật -> App Password -> Sign in password -> SelectApp -> Other -> gõ tên mật khẩu -> sinh ra 1 password mới thay thế cho password hiện có để ứng dụng có tên đó truy cập vào đc gmail của ta 
URL: https://myaccount.google.com/security



# Debug và log trong nodejs
-> Debug nodejs
node --inspect index.js -> mở devtool của chrome lên sẽ thấy option nodejs (k thấy thì gõ chrome://inspect/#devices) -> click là thấy console của nodejs trong browser
Console của browser sẽ giúp nodejs nhìn rõ chi tiết mọi object. Có thể tương tác trực tiếp in ra biến trong browser khi api chạy dừng ở breakpoint.
File js chạy phát tắt ngay thì k thể mở được devtool. Có thể cho server lắng nghe ở 1 cổng lâu để dùng. 
Click đúp vào dòng nào trong tab Source để đặt breakpoint, khi call api sẽ dừng ngay tại đó, F10 đi tiếp. Đặt "debugger;" trong code thì devtool browser cũng hiểu là dừng ở đó

-> Ghi log: Trong hệ thống qtr về tốc độ, việc ghi log tốn thời gian thì thường push message vào buffer r chạy 1 thread riêng lấy ra ghi.
=> Dùng winston ghi log thay morgan, phải tự viết 1 middleware log request bằng winston chứ k tự động. Còn có winston-elasticsearch để kết hợp nó với tool elasticsearch (chatgpt)
URL: https://www.youtube.com/watch?v=ZwDpGJmGGb8&t=150s

Kết hợp với winston-daily-rotate-file để config như maxsize, tự động xóa sau bao nhiêu ngày, tên file chia theo thời gian, định dạng ngày tùy chỉnh, zipfile 
URL: https://www.youtube.com/watch?v=6_DJEZ7285Q

-> Package debug có sẵn trong nodejs giúp log ở môi trường debug:
VD: const debug = require("debug")("myapp:server"); debug("This is message"); => Dùng debug với namespace có tên là myapp:server, namespace có vai trò lọc và phân loại các dòng log debug
Để dùng:
Trong linux: "start": "DEBUG=app:* node app.js" or chạy terminal trực tiếp DEBUG=app:* node app.js
Trong window: cd vào thư mục -> set DEBUG=appmyapp:* => để cho debug trong môi trường nào rồi chạy bth. Làm như này sẽ set biến môi trường của window trong phạm vi thư mục đó

-> Cũng có thể ghi log vào centry or discord.
K nên in chi tiết lỗi quá mức để chỉ đường cho hacker biết thêm thông tin



# Bắt global error
Chạy node index.js có server listen và ta gọi throw thì ct sẽ tự kết thúc vì lỗi unexpected k được bắt. Phải bắt các event lỗi: 
unhandledRejection: rejection nhưng k có handler xử lý 
uncaughtException: phát ra khi uncaught JavaScript exception xảy ra trong event loop
SIGTERM: khi có request program to terminate, VD ta chạy lệnh kill tiến trình này bằng phương tiện nào đó
VD: process.on("uncaughtException", unexpectedErrorHandler); Trong unexpectedErrorHandler thg có process.exit(0); 
Ta có thể override để tắt các connection tới database, socket, close server. Thực tế, nếu tắt process, nó cũng tự close các connection kia rồi, và các công nghệ hiện đại đủ để tự xử lý khi 1 bên tự bị close, phía bên kia cũng tự hiểu điều đó mà ta k cần làm gì thêm.

