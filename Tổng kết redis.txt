Redis
Data bình thường thì dùng database, query nhiều thì dùng cache redis. Với data mang tính nhất thời k cần lưu lâu dài, có thể bỏ qua database và chỉ lưu vào redis, vd bảng xếp hàng game realtime. Nếu chỉ query rất ít thì k nên lưu vào redis.


# Basic
GPT for redis: https://redis.io/chat

Redis lưu kiểu (key, val, expiretime), hỗ trợ transaction. 
Dùng cache tốn thêm bộ nhớ, nên đảm bảo luôn luôn có expire time cho data.

-> Cài đặt: - Có cloud redis https://app.redislabs.com/
- Có app redis: https://redis.io/downloads/ => tut: https://viblo.asia/p/phan-1-cai-dat-redis-co-ban-tuning-redis-bWrZnADYKxw
- Redis insight dùng UI: https://www.youtube.com/watch?v=bkSdxT1Vk4s&t=4s

--> Cài với docker: docker pull redis -> docker run --name myredis -p 6379:6379 -d redis => dùng redis client bình thường tại cổng 6379 => ref tới "Tool / Docker"
Vào terminal redis docker: docker exec -it myredis redis-cli 

Vào máy terminal máy docker: docker exec -it myredis /bin/sh, terminal tối giản cho các image, k có nano hay cat nên buộc phải dùng lệnh từ docker. 
Có thể làm mọi thứ với redis docker, kể cả tạo container, setup haproxy. Nếu file config k tồn tại, chỉ cần tạo mới tại: /usr/local/etc/redis/redis.conf
VD setup đổi port sang 6378: Chuẩn bị file redis.conf với "port 6378" ở local -> vào terminal docker redis -> docker run --name myredis1 -v $(pwd)/test.conf:/usr/local/etc/redis/redis.conf -p 6378:6378 -d redis redis-server /usr/local/etc/redis/redis.conf

-> Cài package với npm: redis-commander => giúp quản lý redis bằng gui
redis (docs chuẩn) hoặc ioredis (nên dùng, cú pháp y hư redis-cli) => để tương tác với redis rất mạnh dùng cho server
redis-cli -> mở để thao tác với cmd: rdcli (phải chờ 1 lát)

-> lazyConnect true khi connect redis sẽ chỉ khởi tạo connection khi cần dùng.



# Xóa cache tối ưu
- Luôn set xoá theo expires time
- Đặt điều kiện xoá data nếu trong 1 tháng k có query. VD dùng event, hoặc mỗi khi query sẽ update lại TTL thành 1 month là được.
- Tạo job chạy vào đêm tự xoá 80% data ít dùng
- Chạy cronjob, với data gần hết expires time thì check, nếu query nhiều thì tự nới rộng TTL, query ít thì xóa đi.
=> Thường chỉ cần expires time là đủ nhưng ta muốn tối ưu nhất có thể, phải xử lý TH bộ nhớ giới hạn cần tối ưu và lưu lượng traffic lớn.



# Redis pipeline
PP batching giúp gửi nhiều lệnh Redis đến server mà không cần chờ phản hồi sau mỗi lệnh. Tăng hiệu suất bằng cách gửi lệnh liên tục rồi nhận tất cả phản hồi đồng loạt 1 lần. Tốc độ bth đã nhanh hơn mysql 20 lần, nhưng dùng pipeline sẽ sẽ nhanh hơn cả ngàn lần.
VD khi cần gọi nh lệnh get: const results = await redis.pipeline().srandmember('colors').llen('users').del('allColors').get('user:10').sadd('talents', 'redis').exec();



# Redis stream
Có thể thêm data, bớt data event khỏi stream, subscribe vào stream với XREAD, XREADGROUP. Dùng để implement hàng đợi bằng redis ok.
Tut: https://www.youtube.com/watch?v=EckRuTo-t0k



# redis-cli và các kiểu dữ liệu
Có nhiều kiểu data: set, string, list, zset (sorted set), hash, bitmap, hyperloglog, GEO, stream

-> Mọi command trong redis-cli đều có dạng code tương ứng:
ping => nhận lại PONG tức connection ok
KEYS a:* => nhận lại tất cả các key trong redis bắt đầu với a:
RANDOMKEY => lấy 1 key ngẫu nhiên
"scan" "0" "MATCH" "*" "COUNT" "500" => lấy 500 phần tử đầu tiên, có phân trang và lấy từ 0
EXISTS <key> => check sự tồn tại 1 key

expire mykey 10 => set expire time cho 1 key có sẵn tên là mykey hết hạn sau 10s
ttl mykey => hiện expire time của mykey

Dùng string:
getrange mykey 0 -1 => lấy tòan bộ ký tự của key tên là mykey
getrange mykey 0 3 => lấy ký tự từ 0 đến 3 của key tên là mykey (getrange mykey <start> <end>)
SET "kavin" 123 
GET "kavin" => sẽ trả lại 123 cho ta, k có trả ra null
set foo bar ex 20 => set giá trị kèm expires time luôn, sau 20s sẽ hết hạn và tự bị xóa khỏi redis
set foo bar ex px 20000 => px biến đổi thành milliseconds
mset user:001:name myname user:001:age 18 => set multiple key-value
mget key1 key2 => lấy multiple key
strlen key1 => lấy length của 1 key
incr/decr key1 => tăng giá trị key1 lên 1, chỉ được nếu key1 là 1 số int
incrby/decrby blog::0001::readcount 10 
SETEX <key> <timeout> "<value>" => set kèm timeout
SETNX <key> "<value>" => key k tồn tại thì set là value, nếu key tồn tại r thì thôi, tức là Set if Not eXist (tx))
DEL <key>

Dùng mảng => khi cần lấy theo range, lấy cả list, lấy theo index, dùng implement stack queue
lpush players a b c => lpush thêm dần từ bên trái nên mảng sẽ thành [c, b, a ]
lpushx movies abc => push phần tử tên là abc vào mảng movies nếu key movies tồn tại, nếu key movies k tồn tại thì k push
lrange players 0 -1 => lấy toàn bộ phần tử trong mảng players
rpush players 1 2 3 => push vào từ bên phải sẽ thành [1, 2, 3]
llen players => lấy length của array
lpop players => xóa 1 phần tử ngoài cùng bên trái và trả về phần tử đó
lpop players 3 => xoá 3 phần tử bên trái
rpop players => tương tự xoá bên phải
lset players 1 Lingrad => thay thế phần tử index là 1 của mảng thành Lingrad
linsert players after Lingrad Martial => insert phần tử mới tên là Martial vào sau phần tử có giá trị là Lingrad trong mảng players, trả về số lượng phần tử mảng
linsert players before Martial Greenwood => tương tự nhưng chèn vào trước phần tử nào
lindex players 2 => lấy cụ thể ptử index là 2 trong mảng
sort players ALPHA => hiển thị mảng sort theo bảng chữ cái
sort players desc ALPHA => ngược bảng chữ cái
llen players => lấy kích thước mảng
lrem players 1 7 => xoá phần tử index là 1 có giá trị là 7
ltrim players 1 4 => xoá và chỉ  để lại phần tử từ index 1 đến index 4
blpop key 0 => loại bỏ và trả về phần tử trái ngoài cùng của list, nếu list trống sẽ chờ trong timeout giây, timeout là 0 sẽ chờ vô hạn. VD dùng cho worker subscribe MQ

Dùng set => khi cần thao tác set operator. VD sở thích chung của nhiều người tìm thông qua giao điểm của 2 tập hợp, quay số random
sadd mykey myvalue1 myvalue2 myvalue3 => thêm 3 phần tử vào set, trả số lượng phần tử thêm thành công 
smembers mykey => hiển thị set
srem mykey myvalue1 => xoá phần tử
scard mykey => lấy số lượng phần tử set (card là cardinality)
srandmember mykey 2 => lấy ngẫu nhiên ra 2 phần tử 
spop mykey 1 => xoá ngẫu nhiên 1 phần tử trong set
smove cr7 m10 valuex => di chuyển phần tử valuex từ set cr7 sang set m10 
sismember mykey value1 => check phần tử value1 có trong tập mykey hay không
sdiff mykey mykey2 => hiển thị phần tử tập mykey có mà mykey2 không có (phải đúng thứ tự)
sdiffstore newset mykey mykey2 => lưu phần tử tập mykey có mà mykey2 không có vào 1 set mới tên là newset
sinter mykey mykey2 => các phần tử chung của 2 set
sinterstore newsetinter mykey mykey2 => lưu các phần tử chung 2 set và 1 set mới tên là newsetinter
sunion mykey mykey2 => show union 2 set
sunionstore newsetunion mykey mykey2 => lưu union 2 set vào 1 set mới tên là newsetunion

Dùng zset => set mà có sort, ví dụ cần lấy sorted bảng xếp hạng
zadd pre:2023 89 manCity 84 arsenal 75 manu 67 liverpool => thêm 5 phần tử vào zset, sort theo số
zrevrange pre:2023 0 -1 => lấy mọi phần tử sort theo chiều giảm dần. 
revrange pre:2023 0 2 WITHSCORES => là lấy 3 phần tử điểm cao nhất, kèm điểm
zrange pre:2023 0 -1 => lấy mọi phần tử chiều tăng dần
zrem pre:2023 manu => xoá phần tử manu khỏi list
zcard pre:2023 => đếm số phần tử
zincrby pre:2023 30 liverpool => tăng điểm sort cho liverpool thêm 30
zrangebyscore pre:2023 75 90 => lấy tăng dần các phần tử có điểm từ 75 đến 90
zscore pre:2023 liverpool => lấy điểm số của 1 phần tử

Dùng hashset => khi cần truy xuất nhanh theo key lấy ra 1 tập hợp trường và giá trị
VD cần lưu vào redis xem 1 user mua sản phẩm nào với số lượng bao nhiêu: hset cart:user-001 product:p-001 1 => lưu vào cart:user-001 -> [product:p-001, 1] vào bảng hash set tại key search là cart:user-001. Trong hệ thống thực tế, họ thường lưu kiểu cart:<userid> hay product:<productid> như v, ta chỉ id vào cache còn sau đó query vào DB lấy data chi tiết sau. K nên lưu các thông tin hay đổi như name hay giá cả vì lưu xong nó giảm giá phát thì dữ liệu cache bị sai
VD tính năng giỏ hàng: Hset cart:01 product01 1 product:02 2 lưu vào cache số lượng và id của product thôi, sau lấy đủ trường thì gọi thêm từ db
hset user:01 name anonystick age 20 => lưu vào user:01->[(name->anonystick),(age->20)]
hget user:01 name => lấy anonystick
hmget user:01 name age => lấy giá trị của nhiều trường 
hgetall user:01 => lấy mọi trường và value của 1 key
hincrby cart:user-001 product:p-001 3 => tăng val thêm 3, nếu muốn giảm thì dùng hincrby với số âm là được
hlen cart:user-002 => lấy số lượng trường của 1 key, k tính các key null
hdel cart:user-002 product:iPhone14 => xóa 1 trường của key search nào
hexists user:01 age => check trường age của key user:01 tồn tại k
HKEYS user:01 => lấy list key
HVALS user:01 => lấy list value
=> Còn có redisJSON lưu data key value với value là kiểu json nhiều trường phức tạp. Ta cũng có thể stringify json lưu với kiểu hash bth

-> string có 3 kiểu encode dựa trên SDS (string dynamic symbol) của C: embedded khi length <= 44 bytes, raw khi length > 44 bytes, int khi là số nguyên
Vd: SET str <44 ký tự> => "object encode str" sẽ ra embstr
SET str <45 ký tự> => sẽ ra raw
SET num 1234 => "object encode num" sẽ ra int

-> Transaction:
MULTI -> bắt đầu 1 transaction. Gõ hàng loạt lệnh sẽ đưa vào hàng đợi -> EXEC sẽ thực hiện tuần tự trong 1 tx
MULTI -> DISCARD -> dừng và rollback 1 tx
=> Nếu sai về cú pháp thì rollback, nếu sai lỗi logic nó vẫn thực hiện VD incrby 1 string. Vì trong redis sai logic vẫn coi là thành công và return message lỗi

MULTI đang thực hiện dở mà có lệnh khác thay đổi cùng trường vẫn sẽ thực hiện thành công.
WATCH -> tạo 1 khoá cho 1 transaction (MULTI) đầu tiên sau nó -> nếu Th trên xảy ra thì transaction sẽ fail
WATCH có tác dụng khoá cho các lệnh sau WATCH và trước EXEC, nên nếu WATCH r SET r MULTI r EXEC cùng trường cũng sẽ cản lại

-> Lệnh quản lý: MONITOR => giám sát hđ 
CLIENT LIST => list connection
INFO
CONFIG GET maxclients => lấy max số lượng connection
CONFIG SET maxclients 
CONFIG GET * => lấy mọi cấu hình
SLOWLOG help 
SELECT <1 số từ 0 đến 15> => chuyển môi trường db

-> Dùng redis pubsub
PSUBSCRIBE o* => lắng nghe mọi thông điệp gửi tới channel có tên thỏa mãn pattern o* là bắt đầu bằng ký tự o, giới hạn phụ thuộc vào bộ nhớ máy
SUBSCRIBE redisChat => tạo và lắng nghe thông điệp gửi đến channel tên là redisChat
PUBLISH redisChat "This is a message" => gửi thông điệp tới channel redis tên là redisChat

Redis pubsub chỉ là 1 cách giao tiếp giữa các services (tương đương kiểu gọi 1 API):
- VD hàm A thay vì gọi API tới services B, A sẽ gửi message vào channel, tính cô lập logic cao. Subscriber và publisher k biết gì về nhau nên cũng dễ dàng thêm hàng loạt subscribers, còn gọi API thì phải biết, phải sửa hàm gọi
- Chỉ dùng với hệ thống lượng request ít. VD 1000 user cùng request và bắn 1000 sự kiện 1 lúc, có thể bị mất message đó.
- Độ tin cậy thấp, chỉ dùng khi giao tiếp nhanh và k cần xác nhận lấy kết quả. Đúng mô hình microservices push vào queue rồi trả về kết quả, kqt xử lý task thành công không.



# Backup và clone
-> Redis tự động lưu data cả trong ổ đĩa: RDB (Redis db backup) tạo bản sao định kỳ dạng file snapshot (mặc định); AOF (append only file) ghi mọi lệnh ghi vào file log và phát lại file để khổi phục data => phải enable.
=> Redis luôn có xác suất mất data nếu ghi rồi tắt luôn mà chưa kịp tạo file snapshot.
Config tùy biến:
VD redis.conf: save 300 1 => tạo snapshot mỗi 300s nếu có ít nhất 1 thay đổi
VD redis.conf: appendonly yes  \n  appendfsync everysec => Ghi vào file mỗi giây

-> Export data redis ra file rồi import vào máy khác:
- SAVE -> sẽ export ngay data hiện tại ngay lập tức ra file dump.rdb, copy nó vào data file của server redis khác và restart là được
SAVE sẽ block redis cho đến khi hoàn thành, BGSAVE sẽ thực hiện trong background và k lock
VD chạy SAVE trên cli docker, rồi "docker exec -it myredis /bin/sh" -> ls là thấy file.rdb
- Dùng redis-commander có sẵn tính năng export import
- Tạo 1 replica làm slave cho instance hiện tại. Nhiều db cloud chỉ cần nhập url của redis vào là nó tự đồng bộ bằng cách biến nó thành replica.

-> Riêng string, có thể tự viết file import và export
VD file import.txt:
SET TUANDA1 1231
SET TUANDA2 1232
EXPIRE TUANDA1 1001
EXPIRE TUANDA2 1002
[root@master-node ~]# redis-cli < import.txt

VD export cũng chỉ là xử lý file:
[root@master-node ~]# redis-cli KEYS "*" > key_export.txt
[root@master-node ~]# cat key_export.txt 
TUANDA1
TUANDA
TUANDA2
[root@master-node ~]# sed -i -e 's/^/GET /g' key_export.txt 
[root@master-node ~]# cat key_export.txt 
GET TUANDA1
GET TUANDA
GET TUANDA2
[root@master-node ~]# redis-cli < key_export.txt > value_export.txt
[root@master-node ~]# cat value_export.txt 
1231
123
1232
[root@master-node ~]# paste key_export.txt value_export.txt 
GET TUANDA1 1231
GET TUANDA	123
GET TUANDA2	1232



# Cấu hình bảo mật redis
URL: https://viblo.asia/p/phan-3-bao-mat-cho-redis-redis-security-Eb85oARkZ2G
Sửa file config thay đổi port
Server và redis chung 1 máy thì k sao. Nếu remote thì để bind 0.0.0.0 (để mọi máy vào được) và config firewall chỉ cho ip của server
Đặt mật khẩu, dùng Access List Redis (ACL)
Xoá các lệnh nguy hiểm dev k cần dùng
K cho redis chạy quyền root
Phân quyền chạy và đọc file tối thiểu (file chạy là 750, file log và config là 640)
Đặt lịch Backup log, config, dump
Bật TLS giữa client và redis-server.

-> ACL: Redis có thể phân quyền như DB, cho phép user nào được truy cập vào keys nào
https://viblo.asia/p/phan-4-access-list-redis-tinh-nang-moi-o-ban-6-E375zAJ2lGW



# Update đồng bộ cache database
Cache luôn phải đồng bộ data với db gốc, khi write sẽ update cả cache và db, khi read sẽ đọc trong cache, không có thì đọc trong DB rồi update vào cache.
Khi cần update data trong cache thì nên delete thay vì update thủ công, cache sẽ tự động được update ở lần get đầu tiên của user.

Do qtr update cache và db k là 1 tx nên có thể bị xung đột khi nhiều người cùng write và read db, cache. Nhiều giải pháp:
- Ta dùng khoá phân tán bi quan hoặc tự implement mutex locking update db rồi update cache. Mọi chỗ updatedb đó trong dự án đều phải lock và update cache.
- Cho từng task vào MQ để lấy thực hiện lần lượt, update db rồi update cache trong 1 task
- Cách duy nhất xử lý mà k biến nó thành tx là update db rồi xoá cache. Nhưng để tránh bước xoá cache lỗi, cos theer xoá cache -> nếu success thì update db -> lại xoá cache
Cách này vẫn lỗi ở 1 số TH hiếm hoi nên vẫn ok và tạm thời là cách tốt nhất hiện tại. VD: user 1 update db và xoá cache, user 2 đọc từ db xong và cbi add vào cache, user 3 ngay lúc đó update db và xoá cache, user 2 bh mới add được vào cache, db và cache sẽ khác data.



# Client side cache
Tính năng redis cho phép client gọi tới redis server rồi lưu cache ngay trong RAM của client để lần sau k cần gọi vào redis nữa, nhanh hơn nữa.
Redis xử lý vấn đề khi có instance khác thay đổi data thì server cần invalidate local cache ở client. Có 2 modes:
- Default mode: redis tạo bảng invalidation, khi client get sẽ thêm client id và key vào bảng đó. Khi key updated, deleted or expired thì server sẽ gửi invalidation message tới client tự xoá khỏi localCache. Client có thể bắt việc đó bằng cách set tracking on + subscribe vào channel "__redis__:invalidate" do server tạo sẵn.
- Breadcasting mode: default mode, k gửi invalidate message tới client với 1 key nếu client chưa từng fetch key đó. Ở mode này thì redis sẽ gửi invalidate message với key theo pattern chỉ định cho mọi client subscribe pattern đó. 
URL: https://www.linode.com/docs/guides/redis-client-side-caching/



# Redis cluster replication
Giải pháp scaling chỉ dùng khi thiếu bộ nhớ hoặc tốc độ xử lý chậm. 

-> Cơ chế Redis cluster: Redis là single thread nên k tận dụng được multicore. Giải pháp sharding chia data ra các cluster giúp tăng instance tối ưu, nhưng khó khăn là kb cần lấy data từ instance nào => Redis cluster dùng Sharding Algorithm giải quyết vấn đề
Sharding algorithm đơn giản là hash key rồi mod để chia vào cluster. Nhưng nếu tăng số instance lên sẽ phải resharding bằng cách tính toán lại toàn bộ key rất lâu.
Redis giải quyết vấn đề resharding: 1 database sẽ có tổng 16383 hash slots xếp vào các cluster. Data được hash rồi mode 16383 chia vào các hash slots. Rồi xếp các hash slots vào các cluster. VD cluster A lưu từ 0 đến 8000, cluster B lưu hash slots từ 8000 đến 16383. Thêm cluster B lưu từ 7000 đến 9000 thì phân phối lại hash slots của A và B sang D là ok.
=> Cấu trúc dữ liệu được lưu tối ưu sao cho việc lấy là nhanh nhất, VD lấy hash slots từ 7000 đến 8000 rất nhanh.

-> Redis cluster có high availability (HA), dù fail vẫn hoạt động bth
VD trong quá trình trigger failed-over, cluster thấy 1 primary shards fails sẽ tự bầu 1 replica khác làm primary shard mà ta k cần làm gì khác thủ công
Cơ chế: trong 1 cluster, các shard và replica tự trao đổi message với nhau và nếu 1 primary shards k reply, sẽ tự phát hiện và bầu 1 replica của shard đó lên thay thế
=> Ta tuỳ ý config quá trình bầu là cần bao nhiêu cluster đồng ý thì trigger failed-over khi tạo cluster.

--> Luôn giữ 1 số lượng lẻ các primary shard và 2 replica cho mỗi primary shards để tránh split brain situation
Network partition là khi hệ thống phân tán bị chia thành nhiều nhóm phân vùng và các vùng k thể tương tác với nhau. Nó xảy ra do lỗi mạng, lỗi phần cứng, hoặc quá tải gây nghẽn làm các nodes k thể tương tác. 
Split-brain situation là 1 dạng của network partition, khi các nodes cô lập tiếp tục chạy độc lập và đưa ra quyết định.
Ở đây, các phân vùng sẽ thấy các nodes ở phân vùng khác là offline và trigger failed over, biến replica thành primary shards. Nếu chia thành 2 phân vùng bằng node nhau, cả 2 sẽ tự cho mình là leader và sẽ tiếp tục nhận request từ clients khiến các phân vùng có cùng primary shards nhưng data khác nhau. Khi network partition được fix, các vùng sẽ merge lại với nhau tự động thì vd thấy 2 primary shards giống nhau ở 2 phân vùng và kb nên chọn cái nào làm primary. Nếu số node lẻ, ngay từ lúc network partition tách ra, phân vùng ít nodes hơn sẽ k tự nhận mình là leader nữa và sẽ k trigger failed over, cũng không nhận request từ client nữa.
=> Nếu gặp split brain situation, phải dùng các giải pháp khác phức tạp hơn như các thuật toán đồng thuận như Paxos, Raft quorum-based consensus, thêm weight cho các node.

-> Các mô hình: https://viblo.asia/p/phan-5-cac-mo-hinh-redis-uu-va-nhuoc-diem-vyDZOR87Kwj
Mô hình đơn / master - slave / master - n slave / SENTINEL / sharding cluster
Replica nhân bản master, cluster là chia 1 master thành nhiều master. Ở sharding cluster, ta có nhiều master, mỗi msaster có các slave replica.

-> https://viblo.asia/p/phan-6-redis-master-salve-su-dung-acl-RnB5pAvbKPG => cách cấu hình 1 master 1 slave dùng ACL
Trong Redis Cluster, mỗi node cần mở hai cổng TCP:
- Cổng chính (6379): là cổng tiêu chuẩn mà Redis sử dụng để giao tiếp với các clients.
- Cổng phụ (cổng chính + 10000, VD: 16379): Cổng này được sử dụng cho việc giao tiếp nội bộ giữa các nút trong cụm Redis

-> https://viblo.asia/p/phan-7-redis-sentinel-su-dung-acl-eW65GpQjKDO => redis sentinel với ACL tự phát hiện master down bầu slave lên

-> https://vnsys.wordpress.com/2019/01/16/ha-redis-sentinel-su-dung-haproxy/ => redis sentinel với HA Proxy để xđ master trong sentinel
https://www.youtube.com/watch?v=TWXTJdcgNoE => chi tiết

-> Tạo cluster và tuỳ biến mọi thứ: https://viblo.asia/p/phan-8-cai-dat-redis-cluster-kiem-tra-cluster-YWOZrPmv5Q0



# Redis keyspace notification
URL: https://redis.io/docs/latest/develop/use/keyspace-notifications/
Keyspace notification cho phép client subscribe vào channel để nhận các event đặc biệt của redis. Có event như: khi 1 data hết hạn, hay khi 1 key mới được set.
VD Tự hủy đơn hàng nếu chưa thanh toán quá N phút: set expires time cho đơn hàng và subscribe sự kiện hết hạn thì thực hiện tuỳ ý.

-> Thao tác cli: thực tế các tính năng kiểu bắt sự kiện đều là dùng channel pubsub của redis
- Mode này mặc định bị disable, phải bật lên với: rdcli config set notify-keyspace-events Ex => thì E là 1 key event, x là bắt sự kiện khi expire
- Mở 1 terminal bắt sự kiện expire với: psubscribe __keyevent@0__:expired
- Mở 1 terminal khác chạy: set orderId:123 123 EX 5 => để set 1 giá trị expire sau 5s, khi đó terminal đầu tiên sẽ bắt được

-> Thao tác với code:
pSubscribe giúp lắng nghe theo 1 pattern. VD: client.psubscribe('user:*');
subscribe giúp lắng nghe 1 channel cụ thể nào. VD: client.subscribe('user:123');



# 3 sự số cache
Nếu 1 query gọi vào db để update lên cache thì k sao, nhưng hàng ngàn request cùng 1 lúc gọi thì k ổn. MySQL trung bình chỉ chịu được 2k request 1s.

-> Cache avalanche: Set nhiều data hết hạn cùng lúc đẩy quá nhiều request đồng thời vào db làm nó sập. 
Giải pháp là thêm randomize expiration cho data hoặc pre-warming cache, locking
Pre-warming cache: đánh dấu các data quan trọng có nhiều người query -> giả sử set expire time của data là 2h, thời gian làm nóng là 15p -> Chạy 1 cronjob mỗi 5p, mỗi lần sẽ check thời gian làm nóng để làm mới cache -> Thêm tí randomize vào, càng gần expiration time thì xác suất làm mới càng tăng.
Locking là kiểu giới hạn các hàm lấy db để làm mới cache, k cho quá nhiều request đồng thời. Có thể bắt người dùng chờ, báo lỗi yêu cầu retry or dùng tạm version cũ của data

-> Cache breakdown: khi 1 key quan trọng trong cache có nhiều người query bị hết hạn khiến tất cả call vào db. VD như mã giảm giá, ta lưu hết vào db, nhưng riêng mã quá hot thì cho lên cache cho nhanh, nó hết 1 phát là call vào db cùng lúc làm sập. Hoặc khi cache sập hoặc somehow mất hết data k rõ nguyên nhân cũng khiến mọi request đổ vào db.
Giải pháp: 
- Implement tự động gạt cầu chì cho hệ thống khi số lượng request tới db cao quá ngưỡng. Khi đó có thể thông báo bảo trì, chạy job khôi phục cache là xong. Làm vậy tốt hơn là để tất cả chạy vào db làm hỏng db k thể khôi phục. 
- Dùng distributed cache trong cache cluster để tăng tính chịu lỗi, 1 cache server sập thì cache server khác backup rồi.
- Dùng mutex locking cho 1 lượng request call tới db làm mới cache thôi, các request khác phải chờ cache có thì mới đi tiếp. Nhưng quá nhiều request chờ có thể sập thì có thể implement hàng đợi or báo lỗi. Do đó các hệ thống lớn bỗng dưng hỏng cache or mất data rất khó để khắc phục, kể cả dùng cách trên thì request của ngừoi dùng vẫn đơ 1 thời gian dài cho đến khi cache khôi phục lại như cũ.
=> Có thể implement mutex bằng khoá bi quan trong redis.
VD: const getData = async get(key) => {
    String value = redis.get(key);
    if (value == null) { 
        if (redis.setnx(key_mutex, 1, 3 * 60) == 1) { // Nếu key chưa tồn tại thì set cho nó, lưu max 3 phút thôi
            value = db.get(key); // nên thêm try catch del mutex
            redis.set(key, value, expiretime); // set cache
            redis.del(key_mutex); // xoa mutex di
        } else { // Nên giới hạn số lần gọi
            sleep(50);
            get(key);  // gọi recursive lại
        }
    } else {
        return value;
    }
}

-> Cache penetration: hacker cố tình tạo hàng triệu request với key rác cố tình k có trong cache khiến server query vào db để tìm. 
Giải pháp: 
- Lọc trước các yêu cầu k hợp lệ ở server => luôn làm
- Khi có query thì gán cache value là null, query db có thì update lên cache, k có thì thôi. Để expires time ngắn tầm 1p để tránh sau này có key đó thật. Nếu bị nhiều thì chặn IP address của hacker luôn
- Bloom Filter là kiểu DS giúp check nhanh sự tồn tại của 1 phần tử trong tập hợp, implement ở server để check trước khi call db. Nếu check là có thì có thể có hoặc không có trong db, nếu check là k thì chắc chắn k có trong db. 

Cơ chế bloom filter là 1 dãy bit, mỗi ptu được hash qua k hàm băm lấy ra k bit bị lật. Nó cho ptu cần check qua k hàm băm lấy ra k bit rồi check với dãy bit gốc để biêt phần tử có thể xuất hiện trong db không.
Bộ nhớ rẻ, check nhanh, xác suất càng chuẩn thì càng nhiều hàm băm. Nhược điểm là db có 1 triệu phần tử sẽ phải thêm cả triệu phần tử vào Bloom Filter khi chạy server, bị lâu nên phải làm ở task nền.
Khi thêm hay xoá phần tử cũng phải update bloom filter. Nhưng khi xoá thì k update được nên phải dùng kiểu Counting Bloom Filter không lưu dãy bit mà lưu dãy số đếm mới được.



# Other
-> redis-benchmark tool test performance. URL: https://www.youtube.com/watch?v=dpDGXbe_LeE

-> Còn có RedisStore được tối ưu chỉ cho lưu session data, cookies data phía server. 

-> Usecase Instagram muốn map 300M bức ảnh với userid tương ứng, yêu cầu tốc độ cao truy cập theo khoá và bộ nhớ k quá 15GB (EC2)
K nên dùng SQL vì các bản ghi kbh update, chỉ insert, chả cần tx, chả có quan hệ bảng. Tối ưu là dùng redis. 
Nếu dùng string tạo đơn giản nhất mỗi key 1 value với "SET media:1155315 939" => tốn 21GB

Redis lưu hash với 2 kiểu dữ liệu ziplist và hashtable tuỳ vào kích thước data. ziplist có nén data nên bộ nhớ rẻ. Còn hashtable k nén data để tăng tốc độ truy vấn.
ziplist hay zipmap là kiểu data nén nhưng k cần giải mã mà vẫn có thể truy cập vào phần tử, nhưng tốc độ truy cập bị giảm dần khi list càng nhiều data, tốn CPU vì nó phải duyệt qua list phần tử.
Cấu hình ziplist: hash-max-ziplist-entries 512 # Số lượng entry tối đa trong một hash để sử dụng ziplist, lớn hơn sẽ dùng hashtable
hash-max-ziplist-value 64 # Kích thước entry tối đa (tính bằng byte) để sử dụng ziplist

Instagram chuyển qua dùn hash: set config hash-max-ziplist-entries con số tối ưu là 1000, lớn hơn sẽ gây áp lực lên CPU quá tải. Tận dụng lợi thế hash bằng cách chia 1000 bucket.
VD: HSET "mediabucket:1155" "1155315" "939" "123" ... => Scale lên 300M key thì bộ nhớ chỉ tốn 5GB

-> Usecase 1 user gửi hàng loạt request bắt phiếu giảm giá, hoặc nhiều user đồng thời mua mà kho còn 1 sản phẩm. 
Cần đảm bảo 1 người k lấy 2 phiếu giảm giá, chỉ 1 user được mua sản phẩm. User có thể refresh trang liên tục, thậm chí dùng tool bắt mã giảm giá.
VD dùng hàm atomic hoặc tạo transaction:
const isGiamGia = async({userId}) => {
    const record = await phieuGiamGia.findOneAndUpdate({
        userId
    }, {
        $setOnInsert: {
            userId,
        },
    }, {
        new: false,
        upsert: true,
    });
    if (!record) {
        this.isGiamGia();
    }
}
VD dùng redis pessimitics lock
const isGiamGia = async({userId}) => {
  const result = await this.redis.setNX(userId, 'true'); // setnx là 1 atom của redis nghĩa là nếu userId k có giá trị thì set là true, có rồi thì k làm gì cả
  if (result === 1) {
    // 1 người chỉ đươc 1 mã giảm giá
  }
}



# Unix socket
Là kiểu kết nối nhanh hơn kiểu TCP bth rất nhiều vì bỏ qua giao thức mạng. 
Chỉ kết nối trên cùng 1 máy nên chỉ dùng cho máy chủ đơn, khi server BE và redis cùng 1 máy.
VD: Tạo redis bằng docker rồi connect với server bằng unix socket cùng 1 máy ok.





# So sánh cache redis
Redis có ACID và hiệu suất cao hơn db bth. Nó chỉ k thể thay thế các db như mysql vì k hỗ trợ truy vấn phức tạp như nối table, hay phân quyền bảo mật. 
Chú ý nếu k cần 2 tính năng đó cũng k nên lưu hết data vào cache vì redis dùng main memory nhỏ dễ bị tràn. 

Redis cung cấp nhiều tính năng như pub/sub, sự kiện, hỗ trợ kiểu dữ liệu phức tạp, có chế độ cluster, lưu data bền bỉ trong đĩa cứng, đơn luồng (nên mỗi lệnh là atomic)
VD: Redis hỗ trợ HyperLogLog là một cấu trúc dữ liệu xác định xấp xỉ số lượng phần tử duy nhất trong một tập hợp lớn mà không cần lưu trữ tất cả các phần tử đó
Memcached giống Redis nhưng thiếu nhiều tính năng, chỉ dùng với string, chỉ lưu trong memory restart là mất. Do đó nó cũng có hiệu suất cao hơn và tải công việc lớn hơn.
=> Ứng dụng nhỏ dùng memcached là được. Còn cần linh hoạt hay tính năng nâng cao thì dùng redis.
