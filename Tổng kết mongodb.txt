# Mongodb
Cluster tập hợp nhiều nodes hđ như 1 system duy nhất, nó klq tới việc chia server ở các vùng miền khác nhau mà là gom nhiều máy cùng 1 function ở 1 khu vực thôi.
1 Cloud Server có nhiều Cluster mongodb, 1 cluster có nhiều database bên trong, 1 database bên trong có nhiều collections tên khác nhau, mỗi collection có nhiều documents bên trong. 
Mongodb lưu dữ liệu dạng BSON, tương tự JSON nhưng mạnh hơn.
Mongodb phù hợp với data linh hoạt, thay đổi nhiều. VD thiết kế module nested comment thì mongodb sẽ phù hợp hơn mysql

-> Cài đặt: - Dùng local docker
- Cloud mongodb server: Dùng mongo atlas. Chọn tạo shared cluster. Sau khi tạo cần vào deployment để connect trong 1 cluster -> vào network access mục security cột bên trái, thêm IP address máy của ta hoặc (0.0.0.0 để accept mọi IP) và chọn connect qua driver sẽ lấy được connection string.
- Tải mongo compass: tải compass sẽ tự tải mongodb server và được thêm vào services trong administrator tools của máy win, có thể tắt service này trong control panel.
Compass có thể connect vào service cổng 27017 (default) để dùng qua UI.

-> 2 kiểu connect mongodb có srv hoặc không
DNS seed list connection format là 1 định dạng chuỗi IP or tên miền để kết nối trong mạng ngang hàng qua DNS, được chia bằng dấu phẩy hoặc xuống dòng. Viết tên miền hay IP đều được vì qua DNS thành IP hết. VD các địa chỉ seed này là ip để hệ thống mới kết nối vào các node có sẵn trong mạng khi khởi động.
- mongodb: là kiểu kết nối truyền thống giúp connect tới 1 or nhiều instance của mongodb, phải liệt kê rõ ra. VD: 
mongodb://username:password@host1:port1,host2:port2/databaseName?replicaSet=myReplicaSet => giúp kết nối tới 1 replica set với 2 máy chủ thành viên
- mongodb+srv: là bản cải tiến đơn giản hơn để kết nối tới cluster. Chỉ cần truyền hostname là tên cluster, và mongodb sẽ tự động phân giải tất cả máy chủ thành viên thông qua DNS SRV record để connect (K cần liệt kê cụ thể host port từng máy mà tự động lấy qua DNS SRV record). DNS SRV records là một loại bản ghi DNS kiểu DNS seed list connection format mà ta phải setup cho bên ngoài connect vào.
VD: mongodb+srv://username:password@myClusterName.mongodb.net/databaseName

Dùng mongodb+srv giúp có connection string gọn, k cần liệt kê từng host port, tự động cân bằng tải và failover. Dùng mongodb atlas tự tạo 3 node tiêu chuẩn và cung srv:
- Primary node nhận các thao tác ghi.
- Secondary node(s) sao chép dữ liệu từ node chính, dùng để đọc hoặc backup.
- Arbiter (tùy chọn) không lưu dữ liệu, chỉ dùng để bầu chọn node mới nếu Primary bị down.
Nếu tự hosting, ta cần tạo ra 1 nhiều code trong cluster, rồi cấu hình DNS SRV record cho domain của ta, cần quyền truy cập và quản lý DNS khá phức tạp. Chạy local thì k support gì cả.



# Scaling connect db hệ thống lớn
-> Connect mongodb trong code:
- Trong dự án lớn, k nên tạo 1 connection mongodb duy nhất, mà nên tạo connection mới ở mỗi query. 
- Connection pool là giải pháp tối ưu, query xong tự trả vào pool để tái sử dụng, setting config autoReconnect reconnectTries đảm bảo connection k bị mất khi k sử dụng.
Lúc mới chạy, nếu server khởi động thành công mà connect db lỗi thì nên dừng ct luôn.
1 connection chỉ xử lý 1 truy vấn ở 1 thời điểm nên nếu poolsize là 5 chỉ có 5 lệnh call db gọi đồng thời, còn lại vào hàng đợi. Poolsize nên lấy từ thực nghiệm tuỳ vào cores trong máy. Tạo 1 hàm check gần quá tải thì notify admin để check ngay.

-> Bth 1 server sẽ fix cứng url của db để query tới db server đó. 
Nếu có 10 vùng trên TG, mỗi vùng 1 DB và 1 server, thì server vẫn fix cứng url của db gần nó nhất để query.
Khi đó server có thể dùng 1 connection pool duy trì 5 connections tới db. Có 100 users query đồng thời sẽ chờ nhau và chỉ dùng trong phạm vi 5 connections trong pool, query tới 1 db thôi.

Vấn đề: ở mỗi vùng ta k chỉ dùng 1 db mà dùng 1 cluster có 10 db, server k thể fix cứng url của 10 db được; nếu 1 user ở vùng khác di chuyển tới vùng này thì phải query vào db cũ chú kp db gần nhất nữa.
Giải pháp là dựng 1 server lưu connection string của mọi db, và thực hiện xử lý logic data của user nào thì trả về connection string của db ở vùng tương ứng. Server có thể đóng vai trò như load balancer trong việc phân phối tải tới các db khác nhau trong 1 vùng. Có tool ProxySQL giúp phân phối tải db như v.
Nếu k, sẽ phải fix các url primary, secondary vào code để cấu hình query get gọi vào secondary, write gọi vào primary.

-> Khi dùng serverless như lamba function và RDS của AWS. 
Mỗi khi lamba function call db, nó tạo 1 connection mới. Vì nó là serverless function, k chạy server truyền thống lắng nghe cổng để mở connection pool.
Khi có 5000 function chạy 1 lúc sẽ có 5000 connections đồng thời. 
Để đạt được như server truyền thống, AWS dùng RDS proxy (Relational Database Service Proxy) duy trì 1 global connection pool để connect vào RDS.
Cơ chế nó lưu 1 lượng fix các connection tới RDS và lamba function call vào vượt quá sẽ chờ để chỉ dùng trong phạm vi số lượng connection đã fix.



# Đánh index
Mongodb dùng BTree, còn MySQL dùng đa dạng nhiều kiểu Hash, B+ Tree tùy chọn lúc tạo index. BTree chỉ khác Binary tree là có >2 con
Nhắc lại BTree lưu node cha có nhiều cục trỏ tới node con, node con lại trỏ tới node cháu được chia theo khoảng. 
Thực tế nó làm như sau: Khóa - Contro 60 - Khóa - Contro 70 - Khóa - Contro 80 - Khóa. Tức số khóa bằng số contro + 1. Khóa sẽ trỏ tới node con, còn Contro lưu data. VD khóa giữa Contro70 và Contro80 sẽ trỏ tới node con >70 và <80

-> Mongodb vẫn dùng prefix rule là đánh index từ trái qua, đúng như cấu trúc của B-Tree. VD: db.test.createIndex({ a: 1, b: 1, c: 1 }) 
=> Truy vấn dùng index là: db.test.find({c: "", a: ""}); db.test.find({b: "", a: ""}); => Vì có a nên chắc chắn có index, b a nhanh hơn c a

-> VD mongosh đánh index:
db.products.insert({productName: "Tips JS", categories: ["TShirt", "phone"], stock: {size: "L", color: "green", quantity: 100}}); 
db.products.find(); 
db.products.createIndex({ productName: 1 }) => đánh index cho trường productName
db.products.createIndex({ "stock.quantity": 1 }) => đánh index cho trường stock.quantity
db.products.getIndexes();
db.products.createIndex({ "stock.quantity": 1, categories: 1 }); => compound index

-> Phân tích truy vấn:
VD JS: var exp = db.products.explain(); exp.find({ productName: "Tips JS" }); => tìm trong db nhưng giải thích cả quy trình tìm, như có dùng index hay không 
- Nếu k có index thì stage hiển thị COLLSCAN, có index sẽ hiển thị IXSCAN
- isMultikey là true nếu ta đánh chỉ mục trên 1 trường mà giá trị của trường đó là 1 mảng. VD trường categories của products trên

VD: db.collectionName.stats({ indexDetails: true }); 
db.collectionName.stats({ indexDetails: {name: "indexName"} }); 
=> Hiển thị thống kê chi tiết hơn như index nào chiếm dung lượng bao nhiêu vì nếu đánh quá nhiều index sẽ ảnh hưởng tới tốc độ ghi và giảm bộ nhớ.

-> Dùng full text seach: 
- Đánh index 'text' cho trường cần full text search. Vd: db.players.createIndex({ "name": "text", "description": "text" });
- Tìm kiếm:
db.players.find({ $text:{ $search: 'ghi ban'} }) => tìm trong các trường được đánh index cứ chứa 1 trong 2 chữ "ghi" và "ban" là lấy. Khoảng trắng là phân cách tìm theo OR
db.players.find({ $text:{ $search: '\"ghi ban\"'} }) => tìm đúng chính xác phải chứa cụm từ "ghi ban"
db.players.find({ $text:{ $search: 'bang dau -chan'} }) => tìm kiếm trong các trường đánh index chứa cụm "bang dau" và k chứa từ "chan"
db.players.find({ $text:{ $search: 'chan phai dau'}}, {score: {$meta: 'textScore'}}) => full text search và lấy ra nh kết quả sắp xếp theo điểm trùng khớp. 
Điểm trùng khớp là 1 số thập phân biểu thị độ khớp của 1 record output so với input cần tìm kiếm. $meta: 'textScore' để tính theo điểm của phép truy vấn $text. Ở đây là sắp xếp giảm dần theo độ khớp với chuỗi tìm kiếm => tính năng fuzzy search



# Mongodb injection
Vd: db.users.findOne({ username: { $gte: input1 }, password: { $gte: input2 } });
Nếu input1 và input2 người dùng nhập là "" thì mọi chuỗi đều lớn hơn chuỗi rỗng sẽ lấy mọi tk.

Vd: const user = await db.collection('users').findOne({ username, password });
User input 1 object: {
  "username": { "$ne": null },
  "password": { "$ne": null }
}

Giải pháp là không viết các query kiểu occho như vậy; dùng thư viện như express-mongo-sanitize để cản input chứa các ký tự như $gt, $ne, $or; validate type của input là string hay object, dùng schema của mongoose hay thư viện như joi để validate type của input.



# Backup replica
Có thể backup db vào file, import file vào db khác

-> VD tạo replica qua docker: update 1 db sẽ tự update các db còn lại
docker network create mongo-replica-network => muốn chạy nhiều instance tương tác với nhau, phải tạo 1 mạng
docker run -d -p 27017:27017 --name mongo1 --net mongo-replica-network mongo --replSet "rs0"
docker run -d -p 27018:27017 --name mongo2 --net mongo-replica-network mongo --replSet "rs0"
docker run -d -p 27019:27017 --name mongo3 --net mongo-replica-network mongo --replSet "rs0"
docker exec -it mongo1 bash
mongosh => vào bash của mongo1
rs.initiate()
rs.add("mongo2:27017")
rs.add("mongo3:27017") => thì mongo1 là primary db, mongo2 và mongo3 là secondary db trong replica set
docker exec -it mongo2 bash
db.getMongo().setReadPref('secondary') => Mặc định mongodb chỉ cho đọc từ primary node trong 1 replica set vì nó đảm bảo read và write sẽ luôn đồng bộ. Ta phải set lệnh này thì secondary db có thể read, nhưng sẽ có delay giữa write và read. Ở đây chỉ có primary mới được write



# Dùng lib mongoose
Object Data Modeling (ODM) là kỹ thuật ánh xạ dữ liệu từ db vào các đối tượng trong mã code NoSQL, còn ORM của relational db thôi.
Mongoose là 1 ODM cho mongodb. URL: https://mongoosejs.com/docs/ => nên dùng prisma hơn, drizzle k hỗ trợ

Dùng extension mongodb snippets for node-js. Gõ: !dmbg
Dùng kèm lib: 
mongoose-paginate-v2 plugin hỗ trợ phân trang cho mongoose
mongoose-sequence là plugin hỗ trợ autoincrement 1 trường nào đó khi tương tác với mongoose

-> Dùng mongoose dự án thực
Dùng singleton pattern chỉ 1 instance sử dụng toàn dự án. Dùng connection pool thì 1 instance quản lý 5 connection tới mongodb.

-> Thêm static function cho schema để gọi global 
Thêm các hàm cho 1 instance của schema
Thêm custom query helper cho schema. Vd: Schema.query.byName. Trong mongoose cũng có sẵn các query helper cho các query phức tạp.
Dùng aggregation để query get với đk vô cùng phức tạp, lấy bất cứ thứ gì từ db.
Dùng populate để query liên kết bảng.
Dùng watch để bắt sự thay đổi của data trong 1 collection
Dùng cursor duyệt qua từng document trong 1 collection
Dùng virtual tạo ra 1 thuộc tính ảo cho schema mà k cần lưu trong db, vd 1 trường được tạo ra từ các trường khác.
Dùng validate để check trước giá trị các trường hiện tại có đúng hay không mà chưa cần update thực sự lên db.
Dùng pre/port middleware cho schema để xử lý trước và sau khi thực hiện các thao tác. Mỗi thao tác thực chất cũng chạy lần lượt qua các middleware nếu đinh nghĩa. 

VD: Dùng ModelName.updateOne({ _id: doc._id }, { $set: { name: 'foo' } }) tương đương với ModelName.findOne tìm ra doc và gán trực tiếp doc.name = "foo" rồi doc.save();

-> Dùng transaction với hàm có sẵn: findOneAndUpdate, findByIdAndDelete, findOneAndReplace, findOneAndRemove, findAndModify
Hoặc tự tạo transaction custom với startSession, startTransaction

VD findAndModify tìm 1 document đầu tiên thỏa mãn và update doc đó. Nó là hàm atomic, tức nó sẽ lock doc mà truy vấn này tìm thấy để đảm bảo k có truy vấn khác sửa đổi.
Giả sử tạo ra 1 database với: db.myCollection.insertMany( [
  { _id: 0, a: 1, b: 1 },
  { _id: 1, a: 1, b: 1 }
] )
=> Sau đó ta chạy song song 2 cái queries giống nhau, mỗi query sẽ như dưới:
db.myCollection.findAndModify({
  query: { a: 1 },
  update: { $inc: { b: 1 }, $set: { a: 2 } }
});
Query 1 tìm thấy _id 0 sẽ lock lại và xử lý. Query 2 tìm thì _id 0 bị lock sẽ bỏ qua, k chờ mà tìm tiếp _id 1 thỏa mãn sẽ xử lý là xong.
=> Chú ý phạm vi lock là từng document, muốn lock toàn bộ thì tự tạo transaction riêng

--> Lưu ý kp hàm nào cũng atomic. 
VD gọi hàm db.collection.updateMany() thì nó chỉnh sửa nhiều document nhưng vc sửa đổi từng doc vẫn là atomic dù operation as a whole k atomic.

-> Khi tạo relation 2 bảng, k nên embedded vào mà nên ref
Khi 1 instance bảng này ref tới nhiều instance bảng khác: one to many là cha ref tới 10 con; one to huge là cha ref tới 1 triệu con quá lớn nên họ thường dùng con ref tới cha thôi.
VD mongodb có thể dùng ghi log trong hệ thống nhỏ, còn hệ thống lớn thường dùng Elastic Search cơ. Khi đó 1 server có 1 triệu log là chuyện bth.

-> Mongodb hỗ trợ update kiểu PATCH nested object, khi có 1 object và chỉ cần update 1 field trong object đó. SQL k hỗ trợ điều này mà phải tự stringify và update cả string.
VD: { a: { b: 1, c: 2 } } => truyền vào 'a.b': "3" sẽ chỉ update a.b mà k xóa mất a.c 



# Sharding trong mongodb
Sharding là pp chia dữ liệu và phân phối vào các server khác nhau. Từng shard cũng có thể có replica riêng để tăng tính khả dụng.
Sharding có tăng tốc độ query khi chia nhỏ data, cũng tránh quá tải máy chủ khi quá nhiều data.

Chỉ cần cài mongodb trên các máy độc lập rồi setup shards phần nào của dữ liệu là xong. Cần chọn shardkey là chia data theo trường nào, có thể chia theo hash hoặc chia theo range. VD có thể chia theo range trường createdDate là mỗi năm data sẽ lưu vào 1 shard riêng.
Khi thêm 1 shard mới vào, mongodb tự có cơ chế reshard chia data vào shard mới theo đúng rules
Nếu 1 shard bị sập, mongodb tự động phát hiện dựa vào cơ chế heartbeat cũng chỉ là các shards gửi tín hiệu check lẫn nhau mỗi 2s. Sau đó có thể bầu replica của shard đó lên. Nếu chủ động xoá 1 shard mà k có replica, sẽ phải thủ công chuyển data từ đó ra các shards khác rồi xoá đi.
Khi query db, query routing của mongodb tự check để biết shards nào có data mà query vào. Nếu query chỉ trong 1 shard, tốc độ sẽ nhanh hơn query nhiều shards.



# Usecase thiết kế nested commentSchema
Cần thiết kế sao cho lấy comment phân trang tốc độ cao theo từng level, ở mỗi level lại lấy phân trang tốc độ cao cho từng level con

- Thuật toán nested comment của joey celko: https://www.youtube.com/watch?v=PE6f66u7KBQ
Comment lưu left, right, parentid. Left right đánh số theo prefix traversal

Add 1 comment mới toanh thì left = max right hiện tại của sản phẩm, right = left + 1
Add 1 comment reply phải update left + 2 mọi bản ghi có left > parent left, update right + 2 mọi bản ghi có right > parent right
=> Update hàng loạt bản ghi nhưng số lượng không nhiều vì chỉ thao tác trong phạm vi nested 1 comment

Search comment con từ parentcommentid. VD Search 1 comment là con của comment [2,8] ta chỉ cần tìm comment có left > 2 và right < 8. Có thể lưu thêm level để lấy từng level hoặc lấy hết con

Khi xóa 1 comment, thường xóa thẳng luôn vì comment kqtr và thường k có nhu cầu tạo lại. Còn thực tế xóa data khác, phải dùng trường isDeleted, hoặc move qua 1 db mới cho các tác vụ restore. 
Phải xóa cả comment con có left >= comment left, right =< comment right. Cũng phải update mọi comment có left > comment right với 1 lượng trừ đi width = right - left + 1. Tương tự update right > comment right với - width = right - left + 1

- Với usecase đơn giản hệ thống nhỏ, chỉ cần lưu thêm parentid với timestamp => ref tới "Project / BlogWeb"
Cách này thì việc lấy và thêm comment đơn giản vì chỉ thao tác với 1 bản ghi. Nhưng delete phải tìm để xóa nested khá lâu.

- PP khác: https://www.youtube.com/watch?v=i8WLvdbF_W8&list=PLw0w5s5b9NK5SUfrJ8rjIMYitT9K8WB8W
1 comment lưu slug (là id), parentslug và timestamp. 
slug của 1 comment = "slug comment cha của cha/slug comment cha/slug comment hiện tại", cứ lồng vào thì slug lại lồng tiếp
Khi thêm sẽ lồng slug cha vào con đơn giản. Có thể lấy tất cả comment con của 1 comment cha với RegExp "slug cha/*", hoặc con ở cụ thể cấp độ 2 với "slug cha/*/*$". Khi xóa cũng dùng RegExp đơn giản, có thể đánh index.



# Tổng kết toán tử trong mongodb
$rename đổi tên một trường (field) 
VD: db.collection.updateOne({ _id: 1 }, { $rename: { "oldFieldName": "newFieldName" } });

$eq	$ne $gt $gte $lt $lte $in $nin
VD: db.users.find({ age: { $gt: 18 } })

$and $or $not $nor
VD: db.users.find({ $or: [{ age: { $lt: 18 } }, { testBool: true }] })

$set $unset $inc
$push Thêm phần tử vào mảng
$pull Gỡ phần tử khỏi mảng
$addToSet Thêm phần tử nếu chưa tồn tại
Vd: db.users.updateOne({ _id: 1 }, { $inc: { points: 10 } })

$all Mảng chứa tất cả các phần tử chỉ định
$elemMatch So khớp phần tử trong mảng
$size Kích thước mảng
VD: db.products.find({ specs: { $elemMatch: { key: "RAM", value: "16GB" } } });

$sum $avg
$group Nhóm dữ liệu
$match Lọc dữ liệu (như find)
$project Chọn trường trả về
VD: db.orders.aggregate([ { $group: { _id: "$customerId", total: { $sum: "$amount" } } } ])



## Mongodb pattern
Còn có: outlier pattern, computed pattern, extended reference pattern, approximation pattern, tree pattern, preallocation pattern, document versioning, schema versioning pattern. 

# Subset pattern
Nhét tất cả data liên quan vào 1 schema giúp thao tác dễ hơn nhưng nếu data lớn k ổn. Vd thiết kế review cho 1 products hay comment cho 1 bài post như trên facebook:
{
  ... data về product ...
  reviews: [
    {
      author: "user1",
      text: "This is content of review",
      rating: 5
    },
    ... 1000 reviews khác ...
  ]
}
=> Làm như v thì mỗi lần query sản phẩm sẽ lấy hết reviews về và hoang phí.

Subset pattern đưa ra giải pháp là chỉ lưu data cần dùng ngay ở trong main collection. Vd:
{
  ... data về product ...
  topFiveReviews: [
    ... Chỉ có 5 review tốt nhất hiện ra ...
  ]
}
=> Khi users query sp sẽ lấy về 5 reviews đáng quan tâm nhất luôn. Ấn xem thêm mới show toàn bộ review với phân trang lấy từ 1 collection Review riêng. Điều này là cần thiết vì review là loại data có thể mở rộng ra vô hạn theo thời gian mà k bị giảm đi, còn 1 document giới hạn max 16MB
=> Có nhiều giải pháp đi kèm như, mỗi comment lưu thêm score, với mỗi request tương tác với comment đó càng nhiều sẽ cộng score lên và ưu tiên show ra. Hoặc cho người dùng vote comment nào lên top trend.

--> Có thể tối ưu hơn nữa bằng cách tạo 1 crawl job cứ mỗi 3 tháng sẽ tự động đẩy 80% dữ liệu review vào collection "Lịch sử cũ" trong trường hợp số lượng review bị nhiều quá, tương tự vơi nhiều kiểu data khác. Đảm bảo bảng review sẽ luôn ít data cần query hơn mà vẫn đảm bảo yêu cầu. 
Trong mongodb mặc định có bộ đệm WiredTiger: tự động lưu các data nằm trong Working Set (là các data được truy vấn nhiều) để tối ưu. Vd nó thường lưu indexed data.
=> Ta k thể tương tác với bộ đệm này nhưng có thể custom qua cấu hình để đáp ứng nhu cầu về hiệu suất, như custom kích thước, cách lưu dữ liệu, quản lý bộ đệm.



# Polymorphic pattern / Attribute pattern
-> Polymorphic pattern
Cơ chế là nên lưu các kiểu dữ liệu khác nhau vào chung 1 collection nếu gom được các thuộc tính chung của chúng.
VD: 1 db lưu 100 loại sản phẩm khác nhau như tai nghe, quần áo, thú cưng vì có cùng các thuộc tính như tên, giá, quantity, ảnh minh họa. Chứ k nên chia ra kiểu ElectronicCollection, PetCollection, ClothesCollection quản lý rất khó khi mở rộng

-> Attribute pattern
Polymorphic pattern tạo 1 collection cho nhiều kiểu data khác nhau. Nhưng mỗi data vẫn có các thuộc tính riêng. 
VD Đồ điện tử có tên hãng, màu sắc:
attributes: {
  brand: "apple",
  color: "silver"
}
Quần áo có kích thước, chất liệu:
attributes: {
  size: "L",
  material: "cotton"
}

Kiểu gì cũng phải dùng index vì người dùng chắc chắn muốn search sản phẩm theo thuộc tính riêng với tốc độ cao nhưng đánh index từng trường sẽ chết bộ nhớ. Attribute pattern giải quyết bằng cách biến mọi attribute thành 1 mảng có cấu trúc chung:
VD đồ điện tử dùng
attributes: [
  { k: "brand", v: "apple" },
  { k: "color", v: "silver" }
]
Còn quần áo dùng
attributes: [
  { k: "size", v: "L" },
  { k: "material", v: "cotton" }
]
=> Thì chỉ cần đánh 1 index {k: 1, v: 1} ok. Nếu có trường đặc biệt cần 3 giá trị như { k: "height", v: "97", u: "cm" } thì đánh index thành {k: 1, v: 1, u: 1} là được
=> Mongodb rất mạnh cho phép ta đánh index 1 trường trong 1 object, object này nằm trong 1 mảng là thuộc tính của 1 document trong 1 collection



#***Bucket pattern trong mongodb
Giải pháp tối ưu hóa bản ghi vì 1 bản ghi có thể dài tới 16MB nên việc lưu 1 comment = 1 record rất tốn. Ta nên lưu 1 records = 1 list comment con của 1 comment trong 1 sản phẩm với giới hạn 1000.
VD bucket có parent id là null sẽ chứa comment gốc. Bucket có parent id là 1 comment sẽ chứa 1000 comment con của comment đó, nếu lớn hơn 1000 sẽ lưu ở bucket có parentid tương tự nhưng sang page 2.
Khi thêm chỉ update vào bucket đơn giản. Khi lấy sẽ lấy theo bucket parentid và page. Khi xóa thì xóa toàn bộ comment con là bucket có parent id là comment đó.

Comment k có filter phức tạp nên làm v là ổn. Trong thực tế, việc thiết kế phụ thuộc vào frontend sẽ lấy nó như nào để tối ưu. VD Nếu frontend lấy 1 comment thì cần lấy hết các comment con mọi cấp độ thì dùng joey celko là chuẩn nhất.
Bucket pattern cũng dùng kiểu chia để tránh 1 collection chứa quá nhiều document. Vd chia thành các table con 1, table con 1 như quyển sách chia thành tập 1, tập 2 vậy.
MongoDb khuyến nghị sử dụng máy chủ ít nhất 64GB RAM phần cứng cho dữ liệu lớn. 1 collection trong mongodb cho có thể lưu tới 32TB document. 1 document có max kích thước là 16MB. 1 document có thể nested object tới 100 lần => lưu thoải mái mà chả qt bộ nhớ. 

VD dùng mongodb ghi log để thống kê request theo từng phút trong hệ thống gồm nhiều server phức tạp:
{
  _id: ObjectId("0000001");
  data_received: "2022-03-30 00:01:000",
  server_id: "111",
  infor: {
    ip: "ip của server",
    cpu: "xx",
    ram: "xx"
  },
  request_calls: 12000,
  failed_calls: 1200
}
=> Tức là mỗi phút sẽ sinh ra 1 documents log như v cho 1 server cần quản lý. 1 ngày có tới 1400 documents rất tốn. Fix với bucket pattern

-> Tối ưu với bucket pattern:
{
  data_received: "2022-03-30 01:00:000",
  server_id: "111",
  infor: {
    ip: "ip của server",
    cpu: "xx",
    ram: "xx"
  },
  request_calls: {
    minutes: [
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
    ],
    sum: 190071
  },
  failed_calls: {
    minutes: [
      1200, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
      12000, 10000, 200, 90, 1, 2, 3, 4, 5, 90,
    ],
    sum: 78977
  }
}
=> Tức thay vì 1 phút sinh 1 document mới thì mỗi 1h mới tạo 1 document mới, còn trong 1h đó chỉ cần update document cũ. Gom lại vào 1 mảng data liên tục thôi.

-> Ta có thể tối ưu hơn nữa rằng 1 ngày mới sinh ra 1 document mới.
{
  data_received: "2022-03-30",
  server_id: "111",
  infor: {
    ip: "ip của server",
    cpu: "xx",
    ram: "xx"
  },
  request_calls: {
    mesurements: {
      "1": [10000, 12, 123, ... ], // Lưu 60 phần tử là từng phút trong giờ đó
      "2": [10000, 12, 123, ... ],
      ...
      "24": [10000, 12, 123, ... ],
    },
    sum: 909099
  },
  failed_calls: {
    mesurements: {
      "1": [10000, 12, 123, ... ],
      "2": [10000, 12, 123, ... ],
      ...
      "24": [10000, 12, 123, ... ],
    },
    sum: 8980980
  }
}


