//!!!!!!!!
# Basic
1 Cloud Server có nhiều Cluster, 1 cluster có nhiều database bên trong, 1 database bên trong có nhiều collections tên khác nhau, mỗi collection có nhiều documents bên trong. 
Còn model hay schema trong code là tùy vào thư viện như mongoose sử dụng để định nghĩa ra cấu trúc của 1 collection.
Mongodb lưu dữ liệu dạng BSON, tương tự JSON nhưng mạnh hơn.
Mongodb phù hợp với data linh hoạt, thay đổi nhiều. VD thiết kế module comment thì mongodb sẽ phù hợp hơn mysql

URL docs: https://mongoosejs.com/docs/
URL tut: https://stackjava.com/huong-dan-mongodb-code-vi-du-java-mongodb

-> Cài đặt: - Cài local docker
- Cloud mongodb server: Dùng mongo atlas. Chọn tạo shared cluster. Sau khi tạo cần vào deployment để connect trong 1 cluster -> vào network access mục security cột bên trái, thêm IP address máy của ta hoặc (0.0.0.0 để accept mọi IP) và chọn connect qua driver sẽ lấy được connection string.
- Tải mongo compass: Khi tải compass về sẽ tự tải mongodb server và được thêm vào services trong administrator tools của máy win, có thể tắt service này trong control panel. 
Compass có thể connect vào service cổng 27017 (default) để dùng qua UI.

-> 2 kiểu connect mongodb có srv hoặc không
DNS seed list connection format là 1 định dạng chuỗi IP or tên miền để kết nối trong mạng ngang hàng qua DNS, được chia bằng dấu phẩy hoặc xuống dòng. Viết tên miền hay IP đều được vì qua DNS thành IP hết. VD các địa chỉ seed này là ip để hệ thống mới kết nối vào các node có sẵn trong mạng khi khởi động.
- mongodb: là kiểu kết nối truyền thống giúp connect tới 1 or nhiều instance của mongodb, phải liệt kê rõ ra. VD: 
mongodb://username:password@host1:port1,host2:port2/databaseName?replicaSet=myReplicaSet => giúp kết nối tới 1 replica set với 2 máy chủ thành viên
- mongodb+srv: là bản cải tiến đơn giản hơn để kết nối tới cluster. Chỉ cần truyền hostname là tên cluster, và mongodb sẽ tự động phân giải tất cả máy chủ thành viên thông qua DNS SRV record để connect (K cần liệt kê cụ thể host port từng máy mà tự động lấy qua DNS SRV record). DNS SRV records là một loại bản ghi DNS kiểu DNS seed list connection format mà ta phải setup cho bên ngoài connect vào.
VD: mongodb+srv://username:password@myClusterName.mongodb.net/databaseName
=> Để server mongodb hỗ trợ kiểu connect "mongodb+srv", có thể dùng mongodb atlas sẽ tự động setup (DNS SRV record) sẵn cho ta vì nó hosting hộ hết r. Nếu tự hosting, ta cần cấu hình DNS SRV record cho domain của ta, cần quyền truy cập và quản lý DNS khá phức tạp. Còn nếu chạy local thì nên dùng mongodb bth vì k hỗ trợ mongodb+srv



# Đánh index
Mongodb dùng BTree, còn MySQL dùng đa dạng nhiều kiểu Hash, B+ Tree tùy chọn lúc tạo index. BTree chỉ khác Binary tree là có >2 con
Nhắc lại BTree lưu node cha có nhiều cục trỏ tới node con, node con lại trỏ tới node cháu được chia theo khoảng. 
Thực tế nó làm như sau: Khóa - Contro 60 - Khóa - Contro 70 - Khóa - Contro 80 - Khóa. Tức số khóa bằng số contro + 1. Khóa sẽ trỏ tới node con, còn Contro lưu data. VD khóa giữa Contro70 và Contro80 sẽ trỏ tới node con >70 và <80

-> VD mongosh đánh index:
db.products.insert({productName: "Tips JS", categories: ["TShirt", "phone"], stock: {size: "L", color: "green", quantity: 100}}); 
db.products.find(); 

db.products.createIndex({ productName: 1 }) => đánh index cho trường productName
db.products.createIndex({ "stock.quantity": 1 }) => đánh index cho trường stock.quantity
db.products.getIndexes();
db.products.createIndex({ "stock.quantity": 1, categories: 1 }); => compound index

-> Phân tích truy vấn
VD JS: var exp = db.products.explain(); exp.find({ productName: "Tips JS" }); => tìm trong db nhưng giải thích cả quy trình tìm, như có dùng index hay không 
- Nếu k có index thì stage hiển thị COLLSCAN, có index sẽ hiển thị IXSCAN
- isMultikey là true nếu ta đánh chỉ mục trên 1 trường mà giá trị của trường đó là 1 mảng. VD trường categories của products trên

VD: db.collectionName.stats({ indexDetails: true }); 
db.collectionName.stats({ indexDetails: {name: "indexName"} }); 
=> Hiển thị thống kê chi tiết hơn như index nào chiếm dung lượng bao nhiêu vì nếu đánh quá nhiều index sẽ ảnh hưởng tới tốc độ ghi và giảm bộ nhớ.

-> Mongodb vẫn dùng prefix rule là đánh index từ trái qua, đúng như cấu trúc của B-Tree. VD: db.test.createIndex({ a: 1, b: 1, c: 1 }) 
=> Truy vấn dùng index là: db.test.find({c: "", a: ""}); db.test.find({b: "", a: ""}); => Vì có a nên chắc chắn có index, b a nhanh hơn c a



# Mongodb injection
VD: db.users.findOne({ username: { $gte: "" }, password: { $gte: "" } });
=> Cản với mongo-santinize: db.users.findOne(santinize({ username: { $gte: "" }, password: { $gte: "" } }));



# Backup replica
-> Có thể backup db vào file, import vào db khác

-> Tạo replica qua docker: update 1 db sẽ tự update các db còn lại
docker network create mongo-replica-network => muốn chạy nhiều instance tương tác với nhau, phải tạo 1 mạng
docker run -d -p 27017:27017 --name mongo1 --net mongo-replica-network mongo --replSet "rs0"
docker run -d -p 27018:27017 --name mongo2 --net mongo-replica-network mongo --replSet "rs0"
docker run -d -p 27019:27017 --name mongo3 --net mongo-replica-network mongo --replSet "rs0"
docker exec -it mongo1 bash
mongosh => vào bash của mongo1
rs.initiate()
rs.add("mongo2:27017")
rs.add("mongo3:27017") => thì mongo1 là primary db, mongo2 và mongo3 là secondary db trong replica set
docker exec -it mongo2 bash
db.getMongo().setReadPref('secondary') => Mặc định mongodb chỉ cho đọc từ primary node trong 1 replica set vì nó đảm bảo read và write sẽ luôn đồng bộ. Ta phải set lệnh này thì secondary db có thể read, nhưng sẽ có delay giữa write và read. Ở đây chỉ có primary mới được write



# Dùng mongoose
Object Data Modeling (ODM) là kỹ thuật ánh xạ dữ liệu từ db vào các đối tượng trong mã code. Mongoose là 1 ODM cho mongodb. 

-> Thêm static function cho schema gọi global 
Thêm các hàm cho 1 instance của schema
Thêm custom query helper cho schema. Vd: Schema.query.byName. Trong mongoose cũng có sẵn các query helper cho các query phức tạp.

Dùng aggregation để query get với đk vô cùng phức tạp.
Dùng populate để query liên kết bảng.
Dùng watch để bắt sự thay đổi của data trong 1 collection
Dùng cursor duyệt qua từng document trong 1 collection
Dùng virtual tạo ra 1 thuộc tính ảo cho schema mà k cần lưu trong db, vd 1 trường được tạo ra từ các trường khác.
Dùng validate để check trước giá trị các trường hiện tại có đúng hay không mà chưa cần update thực sự lên db.
Dùng pre/port middleware cho schema để xử lý trước và sau khi thực hiện các thao tác. Mỗi thao tác thực chất cũng chạy lần lượt qua các middleware nếu đinh nghĩa. 

VD: Dùng ModelName.updateOne({ _id: doc._id }, { $set: { name: 'foo' } }) tương đương với ModelName.findOne tìm ra doc và gán trực tiếp doc.name = "foo" rồi doc.save();

-> Dùng kèm lib: 
express-mongo-sanitize: package dùng cho express khi dùng mongodb có thể xử lý input tránh Injection
mongoose-sequence: plugin hỗ trợ autoincrement 1 trường nào đó khi tương tác với mongoose
mongoose-paginate-v2 plugin hỗ trợ phân trang cho mongoose

-> Dùng transaction:
Hàm có sẵn: findOneAndUpdate, findByIdAndDelete, findOneAndReplace, findOneAndRemove
Cũng có thể tự tạo transaction custom với startSession, startTransaction

VD: Khi 1 người gọi hàm db.collection.updateMany() chẳng hạn thì nó chỉnh sửa nhiều document nhưng vc sửa đổi từng doc vẫn là atomic dù operation as a whole thì k atomic.

VD: findAndModify là hàm atomic, tức nó sẽ lock document mà truy vấn này tìm thấy để đảm bảo k có truy vấn khác sửa đổi.
Giả sử tạo ra 1 database với: db.myCollection.insertMany( [
  { _id: 0, a: 1, b: 1 },
  { _id: 1, a: 1, b: 1 }
] )
=> Sau đó ta chạy song song 2 cái queries giống nhau, mỗi query sẽ như dưới:
db.myCollection.findAndModify( {
  query: { a: 1 },
  update: { $inc: { b: 1 }, $set: { a: 2 } }
} )
Query 1 tìm thấy _id 0 sẽ lock lại và xử lý. Query 2 k chờ cái lock đó mà thực hiện tiếp sẽ tìm và xử lý với _id 1 và hoàn thành. Query 1 hoàn thành xử lý _id 0 sẽ mở lock _id 0 và thực hiện _id 1, còn query 2 k recheck _id 0 mà bỏ qua luôn.
=> Chú ý phạm vi lock là từng document, muốn lock toàn bộ thì tự tạo transaction riêng



# Code mẫu option cho Schema
level1: new Schema({
  level2: new Schema({
    test: String
  })
})
name: mongoose.Schema.Types.String,
date: {
  type: Date,
  default: Date.now,
  min: ['2025-12-09', "Ngày bị nhỏ quá rồi"],
  max: '2019-19-02'
},
age: { type: Number, min: 18, max: 65 },
array: [],
dateArray: [Date],
docArr: [{name: String}],
singleNested: new Schema({ name: String }),
nested: {
  age: Number
  first: { 
    type: String, 
    lowercase: true, 
    uppercase: false, 
    trim:true, 
    minlength: 2, 
    match: "Hello", 
    required: function() { this.age > 0 } 
  }
},
mapOfString: { type: Map, of: String },
details: {
  first: String,
  type: {
    type: String
  }
},
data: {
  type: Number,
  get: v => Math.round(v),
  set: v => Math.round(v),
  alias: "d"
  index: true,
  unique: true,
  sparse: false,
  enum: [1, 2],
  validate: () => Promise.resolve("OK"); => là validate bất đồng bộ
},
phone: {
  type: String,
  validate: {
    validator: function(v) { return /\d{3}-\d{3}-\d{4}/.test(v); },
    message: props => "not a number"
  },
  select: false
  toJSON: { virtuals: true },
  toObject: { virtuals: true }
}
var schema1 = new Schema({
  author: { type: Schema.Types.ObjectId, ref: "Person5" } => ref đến model "Person5" cột _id
});
var commentSchema = new Schema({
  body: {type: String},
  on: {type: ObjectId, required: true, refPath: "onModel"},
  onModel: {type: String, enum: ["BlogPost", "Product"]} => bảng này ref tới 1 trong 2 bảng BlogPost và Product thông qua cột _id
});
=> khi gọi .populate("on") thì nó chạy vào thấy refPath và nhảy vào trường onModel. Trong đây nó sẽ check trường onModel là gì và lấy type: ObjectId là ref "on" với _id của bảng đó, trùng thì lấy

-> Lib mongoose-autopopulate là plugin hỗ trợ thêm 1 số tùy chọn SchemaType 



# Sharding trong mongodb
Replica là sử dụng cluster, còn sharding là pp chia dữ liệu và phân phối vào các server khác nhau. Có thể cho mỗi shard 1 replica để tăng tính khả dụng của hệ thống
Sharding không tăng tốc độ query, mà giúp tăng tính khả dụng khi 1 shard sập thì vẫn hoạt động, tránh quá tải 1 máy chủ duy nhất khi quá nhiều data.

Chỉ cần cài mongodb trên các máy độc lập rồi setup shards phần nào của dữ liệu là xong. Cần chọn shardkey là chia data theo trường nào, có thể chia theo hash hoặc chia theo range. VD có thể chia theo range trường createdDate là mỗi năm data sẽ lưu vào 1 shard riêng.
Khi thêm 1 shard mới vào, mongodb tự có cơ chế reshard chia data vào shard mới theo đúng rules
Nếu 1 shard bị sập, mongodb tự động phát hiện dựa vào cơ chế heartbeat cũng chỉ là các shards gửi tín hiệu check lẫn nhau mỗi 2s. Sau đó có thể bầu replica của shard đó lên. Nếu chủ động xoá 1 shard mà k có replica, sẽ phải thủ công chuyển data từ đó ra các shards khác rồi xoá đi.
Khi query db, query routing của mongodb tự check để biết shards nào có data mà query vào. Nếu query chỉ 1 shard, tốc độ sẽ nhanh hơn query nhiều shards.






# 3 cách connect db:
- K nên tạo 1 db connection global duy nhất dùng suốt dự án. Vì connection có thể đóng vì nhiều lý do mà ko biết như timeout hay lỗi mạng. Kể cả có setting reconnect hay sự kiện disconnect để gọi connect lại cũng k nên dùng
- Mỗi lần query sẽ khởi tạo connection và đóng ở cuối. Duwj asn lowsn
- Connection pool là giải pháp tối ưu, query xong tự trả vào pool để tái sử dụng, setting config autoReconnect reconnectTries, tự đảm bảo connection k bị mất khi k sử dụng.
Néu server khởi động thành công mà connect db lỗi thì nên dừng ct, có thể throw error để dùng.




# Mongodb
-> Comment Schema: Cần thiết kế sao cho lấy comment phân trang tốc độ cao theo từng level, ở mỗi level lại lấy phân trang tốc độ cao cho từng level con

- Thuật toán nested comment của joey celko: https://www.youtube.com/watch?v=PE6f66u7KBQ&t=1s
Add: Comment lưu left, right, parentid. Left right đánh số theo prefix traversal
Add 1 comment mới toanh thì left = max right hiện tại của sản phẩm, right = left + 1
Add 1 comment reply phải update left + 2 mọi bản ghi có left > parent left, update right + 2 mọi bản ghi có right > parent right
=> Số lượng không nhiều vì chỉ thao tác trong phạm vi nested 1 comment

Search comment con từ parentcommentid. VD Search 1 comment là con của comment [2,8] ta chỉ cần tìm comment có left > 2 và right < 8. Có thể lưu thêm level để lấy từng level hoặc lấy hết con

Khi xóa 1 comment, ta có thể dùng trường isDeleted. Với hệ thống lớn, ta nên move qua 1 db mới cho các tác vụ cần hoàn tác hay restore.
Xóa comment có left >= comment left, right =< comment right
Update mọi comment có left > comment right với 1 lượng trừ đi width = right - left + 1. Tương tự update right > comment right với - width = right - left + 1

- ref tới "Project / BlogWeb"
1 cách đơn giản hơn là comment ta chỉ lưu thêm parentid với timestamp. Khi đó việc lấy và thêm comment rất đơn giản vì chỉ thao tác với 1 bản ghi. Việc delete comment nếu làm 1 bản ghi sẽ bị lưu thừa data, nên nếu xóa tất cả phải for loop rất mệt
=> Cái này phù hợp với hệ thống nhỏ như comment của shopee chỉ có max 1 level. Còn thuật toán joey celko có thể nói là độ phức tạp tương đương nhưng phù hợp hệ thống lớn khi có thể lồng rất nhiều cấp độ. Có thể truy vấn 1 phát mọi nested sets con luôn chứ k cần truy vấn từng cấp độ

- Cải tiến: https://www.youtube.com/watch?v=i8WLvdbF_W8&list=PLw0w5s5b9NK5SUfrJ8rjIMYitT9K8WB8W&index=48
Có 1 pp khác cải tiến đơn giản hơn là dùng slug (là id), parentslug và timestamp. slug của 1 comment = "slug comment cha của cha/slug comment cha/slug comment hiện tại", cứ lồng vào thì slug lại lồng tiếp
Khi thêm sẽ lồng slug cha vào con đơn giản. Có thể lấy tất cả comment con của 1 comment cha với RegExp "slug cha/*", hoặc con ở cụ thể cấp độ 2 với "slug cha/*/*$". Khi xóa cũng dùng RegExp đơn giản, có thể đánh index.

Để phân trang: Các giải pháp trước ta có thể phân trang theo kiểu chỉ phân trang các comment ở node gốc. Còn con của 1 comment có thể lấy hết mọi cấp hoặc lấy hết theo từng level, hoặc phân trang ở từng level.

- Subset pattern
Ở mỗi database bài viết gốc, ta lưu 1 trường topFiveComment, khi người dùng xem thêm mới load cho họ thôi từ 1 bảng Comment độc lập và chắc chắn bảng đó phải đánh index rồi
Để có topFiveComment, mỗi comment sẽ lưu thêm score, với mỗi request tương tác với comment đó càng nhiều sẽ cộng score lên và ưu tiên show ra

- Bucket pattern:
Giải pháp tối ưu hóa bản ghi vì 1 bản ghi có thể dài tới 16MB nên việc lưu 1 comment = 1 record rất tốn. Ta nên lưu 1 records = 1 list comment con của 1 comment trong 1 sản phẩm với giới hạn 1000.
VD bucket có parent id là null sẽ chứa comment gốc. Bucket có parent id là 1 comment sẽ chứa 1000 comment con của comment đó, nếu lớn hơn 1000 sẽ lưu ở bucket có parentid tương tự nhưng sang page 2.
Khi thêm chỉ update vào bucket đơn giản. Khi lấy sẽ lấy theo bucket parentid và page. Khi xóa thì cần xác định rõ bucketid là gì và comment nào, nên nhớ để xóa thì người dùng phải chọn nó đồng nghĩa frontend phải truyền lại bucketid cho backend xóa chứ backend k thể search trong toàn bộ bucket được.

Chính vì comment k có filter phức tạp nên làm v là ổn. Trong thực tế, việc thiết kế phụ thuộc vào frontend sẽ lấy nó như nào để tối ưu. VD Nếu frontend lấy 1 comment thì cần lấy hết các comment con mọi cấp độ thì dùng joey celko là chuẩn nhất.

-> Notification system: Giải quyết vấn đề 1 triệu shop gửi notification, 1 triệu user nhận được notification cùng lúc. Tốc độ cao và nhanh. Chắc chắn phải push notification tới user. Chỉ có MQ là đảm bảo tốc độ cao và không mất dữ liệu, không duplicate dữ liệu, đúng thứ tự.

Shop -> new product -> MessageQueue 1 -> User id từ 0 tới 1000
                    -> MessageQueue 2 -> User id từ 1000 tới 2000
=> Phân chia đảm bảo tốc độ push notification đạt tối đa khi có nhiều user

Phân tích:
Shop -> new product -> system.center.notification -> MQ -> 1,000,000 users

Về business: Notification center là database sẽ lưu tất cả notification của mọi shop. Trong 1 triệu user, user nào thường xuyên online, ta sẽ push notification tới cho họ. User nào online ít thì khi nào online, họ phải tự vào notification center mà pull về. Riêng trường hợp mã giảm giá hay tin quan trọng, sẽ phải push tới mọi user.

CrawlJob: Tại sao lại dùng 1 crawljob lấy data từ db của system.center.notification gửi tới MQ mà không gửi mẹ từ shop tới MQ luôn? 
Ta cần tính toán tới việc phân tác các case khi crash hệ thống. Trong trường hợp này cần đảm bảo khi 1 shop gửi notification tới user thành công, chắc chắn notification đó k bị mất khi crash hệ thống, nếu crash thì phải là chưa gửi chứ không phải là gửi thành công nhưng lại crash. Bởi vì việc gửi tới 1 triệu user phải làm từ từ, không thể chờ gửi hết 1 triệu mới báo thành công được. Do đó thành công ở đây là lưu thành công vào system.center.notification. Sau đó cần có 1 crawljob lấy từ db ra gửi vào MQ. 
Lại phải đảm bảo ở từng bước này, hệ thống crash tiếp nhưng khi khởi động lại vẫn chạy tiếp từ chỗ cũ. CrawlJob chỉ cần check trường isSent = false thì gửi tiếp thôi.

Việc phân phối trực tiếp từ system.center.notification tới database của user, so với gửi vào MQ và MQ gửi tới 1 triệu user có điểm lợi gì?
MQ cung khả năng đảm bảo tin nhắn không bị mất, mỗi thông báo chắc chắn sẽ được gửi đi ngay cả khi hệ thống lỗi. Ví dụ ta đang chạy for loop duyệt 1 triệu user để update db, chẳng may sập server phát sẽ mất. Để đảm bảo thì mỗi lần gửi user ta lại phải update database là đã gửi rồi, khởi động lại hệ thống sẽ check k gửi lại user đó nữa sẽ rất phức tạp nếu tự impleemnt. Nhưng MQ thì sập, khởi động lại sẽ tiếp tục từ chỗ dừng lại lần trước.
MQ cung khả năng xử lý tùy biến, ta có thể thêm workder để xử lý tin nhắn từ queue mà không cần thay đổi cơ sở hạ tầng của MQ. Kiểm soát số lượng tin nhắn worker xử lý song song, VD nếu CPU tốn quá thì giảm đi 1 chút để hoạt động trơn tru. Tách biệt quá trình tạo thông báo và gửi thông báo. Nếu server crash, MQ vẫn hoạt động bth, vẫn gửi tiếp các tin nhắn trong queue tới user.
MQ cung khả năng xử lý song song, nên nhớ chạy for loop sẽ xử lý tuần tự, k dùng MQ ta sẽ phải tự implement bất đồng bộ việc này khá mệt

Implement database cho noti.center -> implement MQ -> implement crawljob -> Implement server gửi từ MQ sang db user

-> Aggregate trong mongodb:
Nó giúp combine lấy bất thứ gì từ 1 databasse mongodb, lấy mạnh giống như làm với graphql v


